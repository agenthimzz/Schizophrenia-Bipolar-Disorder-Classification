{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Schizophrenia and Bipolar Disorder Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2sfENy_lcvgo",
        "rZCdjE2oc0Ci",
        "75rI5T7mcAHO",
        "5qgdYfbWcTL8",
        "SNdzO8a5cWX7"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmk0g1WHynrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdFAvxfMzHHz",
        "colab_type": "text"
      },
      "source": [
        "# Schizophrenia and Bipolar Disorder Classification\n",
        "\n",
        "Problem Statement: \n",
        "Use ML tools to classify between Schizophrenia and Bipolar Disorder using the dataset in Dataset folder on your google drive. \n",
        "\n",
        "The dataset is in the form of a pickle file (dictionary file). \n",
        "It has 6 feature keys - ALFF, fALFF, .... - and for each feature, 14 different atlas keys - AAL, Power, ..... \n",
        "\n",
        "For your task, you'll be using only the ReHo feature key, and its 14 corresponding atlas keys to classify between Schizophrenia and Bipolar Disorder with >70% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO94gLKBzr7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLyX5j-1zt2W",
        "colab_type": "text"
      },
      "source": [
        "# Loading Google drive link.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMBWNIxfZSFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall statsmodels\n",
        "!pip install statsmodels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43PeU3hNZYm_",
        "colab_type": "text"
      },
      "source": [
        "Restart Runtime after this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmW3yg6Vz82V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dMgopnmZV2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "109eb9e5-f727-4684-e040-887b0ac69ba8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSG-QgW90TbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_pickle(\"/content/drive/My Drive/Datasets/Schizophrenia and Bipolar Disorder Classification/schizophrenia-45_bipolar-disorder-42_multidict_file.pkl\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pThOFcOvv29O",
        "colab_type": "text"
      },
      "source": [
        "# Go to ReHo dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg6ei-CI0h2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = dataset.get('_ReHo_sz_test_')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUEa_5brCxo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a658be4-2da8-4953-9b5e-8295ecee75ff"
      },
      "source": [
        "df.get(\"aal\").shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87, 116)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkokXc8_egeH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "0c9b7828-9047-4705-99ee-25e9c2fd8742"
      },
      "source": [
        "for i,x in enumerate(df):\n",
        "  l = df.get(x)\n",
        "  try:\n",
        "     print(i, x, [len(l), len(l[0])] )\n",
        "  except:\n",
        "      print(i, x, [len(l)] )\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 aal [87, 116]\n",
            "1 harvard_sub_25 [87, 22]\n",
            "2 harvard_cort_25 [87, 96]\n",
            "3 destrieux [87, 148]\n",
            "4 yeo [87, 17]\n",
            "5 basc_multiscale_122 [87, 122]\n",
            "6 basc_multiscale_197 [87, 197]\n",
            "7 basc_multiscale_325 [87, 325]\n",
            "8 basc_multiscale_444 [87, 444]\n",
            "9 power [87, 264]\n",
            "10 dosenbach [87, 160]\n",
            "11 smith20 [87, 20]\n",
            "12 msdl [87, 39]\n",
            "13 smith70 [87, 70]\n",
            "14 Group_Code [87, 9]\n",
            "15 UIC_No [87, 9]\n",
            "16 diag_label [87, 13]\n",
            "17 diag_Code [87]\n",
            "18 sub_idx [87]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwzIVz39ma-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.get('aal')\n",
        "a = pd.DataFrame(X).transpose()\n",
        "y = pd.Series(df.get('diag_Code'), name = 'diag_Code')\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVA6Vk22O-rA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "543a275a-c174-4a31-92d7-0d00a4a90e66"
      },
      "source": [
        "dataset = a.transpose().join(y, how=\"inner\")\n",
        "X = dataset.drop('diag_Code', axis= 1)\n",
        "X.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.903504</td>\n",
              "      <td>-1.379881</td>\n",
              "      <td>1.815419</td>\n",
              "      <td>0.692680</td>\n",
              "      <td>3.219530</td>\n",
              "      <td>1.762107</td>\n",
              "      <td>1.002799</td>\n",
              "      <td>-1.537369</td>\n",
              "      <td>2.796549</td>\n",
              "      <td>0.593156</td>\n",
              "      <td>-0.255145</td>\n",
              "      <td>-2.527846</td>\n",
              "      <td>1.216521</td>\n",
              "      <td>-1.954173</td>\n",
              "      <td>3.158594</td>\n",
              "      <td>0.682909</td>\n",
              "      <td>-1.125890</td>\n",
              "      <td>-3.486496</td>\n",
              "      <td>-0.572924</td>\n",
              "      <td>-0.489566</td>\n",
              "      <td>2.271910</td>\n",
              "      <td>1.970850</td>\n",
              "      <td>0.654350</td>\n",
              "      <td>1.198993</td>\n",
              "      <td>1.852338</td>\n",
              "      <td>2.058460</td>\n",
              "      <td>2.447902</td>\n",
              "      <td>2.860240</td>\n",
              "      <td>0.170609</td>\n",
              "      <td>-3.189064</td>\n",
              "      <td>-0.076566</td>\n",
              "      <td>0.101435</td>\n",
              "      <td>-3.019396</td>\n",
              "      <td>-3.840099</td>\n",
              "      <td>-2.266207</td>\n",
              "      <td>-2.497234</td>\n",
              "      <td>1.306596</td>\n",
              "      <td>-1.818076</td>\n",
              "      <td>0.649514</td>\n",
              "      <td>-0.711509</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.590754</td>\n",
              "      <td>-2.055499</td>\n",
              "      <td>-0.338335</td>\n",
              "      <td>-2.074032</td>\n",
              "      <td>1.068368</td>\n",
              "      <td>-2.211615</td>\n",
              "      <td>1.486702</td>\n",
              "      <td>-0.766578</td>\n",
              "      <td>1.607996</td>\n",
              "      <td>-3.150339</td>\n",
              "      <td>0.182743</td>\n",
              "      <td>-0.325924</td>\n",
              "      <td>3.416064</td>\n",
              "      <td>0.800033</td>\n",
              "      <td>1.229340</td>\n",
              "      <td>-0.058942</td>\n",
              "      <td>1.376947</td>\n",
              "      <td>0.588287</td>\n",
              "      <td>0.631782</td>\n",
              "      <td>-0.295491</td>\n",
              "      <td>-0.547145</td>\n",
              "      <td>-1.670376</td>\n",
              "      <td>0.092478</td>\n",
              "      <td>-1.340845</td>\n",
              "      <td>1.942557</td>\n",
              "      <td>0.378799</td>\n",
              "      <td>2.169678</td>\n",
              "      <td>1.125459</td>\n",
              "      <td>1.377373</td>\n",
              "      <td>1.705051</td>\n",
              "      <td>0.726210</td>\n",
              "      <td>1.139279</td>\n",
              "      <td>0.272070</td>\n",
              "      <td>-0.366589</td>\n",
              "      <td>-1.331913</td>\n",
              "      <td>-0.984530</td>\n",
              "      <td>0.060450</td>\n",
              "      <td>1.089321</td>\n",
              "      <td>0.030443</td>\n",
              "      <td>0.002744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.005250</td>\n",
              "      <td>-0.774012</td>\n",
              "      <td>0.297203</td>\n",
              "      <td>0.567038</td>\n",
              "      <td>-1.553331</td>\n",
              "      <td>2.111693</td>\n",
              "      <td>0.099713</td>\n",
              "      <td>-0.396241</td>\n",
              "      <td>-0.456515</td>\n",
              "      <td>1.884615</td>\n",
              "      <td>0.053794</td>\n",
              "      <td>0.694751</td>\n",
              "      <td>-0.233670</td>\n",
              "      <td>0.277691</td>\n",
              "      <td>0.492492</td>\n",
              "      <td>0.197456</td>\n",
              "      <td>0.372023</td>\n",
              "      <td>0.567832</td>\n",
              "      <td>0.492808</td>\n",
              "      <td>1.240741</td>\n",
              "      <td>-0.292228</td>\n",
              "      <td>1.023248</td>\n",
              "      <td>1.865757</td>\n",
              "      <td>1.119135</td>\n",
              "      <td>-0.889321</td>\n",
              "      <td>-1.299834</td>\n",
              "      <td>-1.373710</td>\n",
              "      <td>-0.191514</td>\n",
              "      <td>-1.253117</td>\n",
              "      <td>0.937337</td>\n",
              "      <td>1.580214</td>\n",
              "      <td>1.032260</td>\n",
              "      <td>3.396746</td>\n",
              "      <td>3.421665</td>\n",
              "      <td>2.736670</td>\n",
              "      <td>1.789535</td>\n",
              "      <td>1.085319</td>\n",
              "      <td>0.268563</td>\n",
              "      <td>0.857363</td>\n",
              "      <td>-0.616249</td>\n",
              "      <td>...</td>\n",
              "      <td>0.908819</td>\n",
              "      <td>-0.425550</td>\n",
              "      <td>0.752101</td>\n",
              "      <td>1.767480</td>\n",
              "      <td>0.222950</td>\n",
              "      <td>-0.265223</td>\n",
              "      <td>0.613497</td>\n",
              "      <td>-1.332714</td>\n",
              "      <td>-0.505441</td>\n",
              "      <td>0.943603</td>\n",
              "      <td>1.851475</td>\n",
              "      <td>0.569340</td>\n",
              "      <td>-0.073796</td>\n",
              "      <td>1.651536</td>\n",
              "      <td>-0.510472</td>\n",
              "      <td>-0.039267</td>\n",
              "      <td>-0.255629</td>\n",
              "      <td>0.234409</td>\n",
              "      <td>-0.477560</td>\n",
              "      <td>-0.091747</td>\n",
              "      <td>0.214220</td>\n",
              "      <td>-0.738331</td>\n",
              "      <td>-0.311251</td>\n",
              "      <td>0.890055</td>\n",
              "      <td>-0.359844</td>\n",
              "      <td>0.842562</td>\n",
              "      <td>-0.061958</td>\n",
              "      <td>0.958803</td>\n",
              "      <td>0.080446</td>\n",
              "      <td>-0.808424</td>\n",
              "      <td>0.353605</td>\n",
              "      <td>-1.609424</td>\n",
              "      <td>-0.520662</td>\n",
              "      <td>1.546322</td>\n",
              "      <td>0.893820</td>\n",
              "      <td>0.352795</td>\n",
              "      <td>-0.259075</td>\n",
              "      <td>1.498940</td>\n",
              "      <td>1.809240</td>\n",
              "      <td>0.952663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.570857</td>\n",
              "      <td>0.659692</td>\n",
              "      <td>-0.606319</td>\n",
              "      <td>-0.922331</td>\n",
              "      <td>-0.181489</td>\n",
              "      <td>-0.669323</td>\n",
              "      <td>0.116768</td>\n",
              "      <td>-0.543971</td>\n",
              "      <td>-0.314008</td>\n",
              "      <td>-0.697251</td>\n",
              "      <td>-0.075673</td>\n",
              "      <td>0.683390</td>\n",
              "      <td>-0.147586</td>\n",
              "      <td>0.520724</td>\n",
              "      <td>-0.031966</td>\n",
              "      <td>-0.642244</td>\n",
              "      <td>0.154361</td>\n",
              "      <td>0.324440</td>\n",
              "      <td>-0.015973</td>\n",
              "      <td>-0.926121</td>\n",
              "      <td>-0.599857</td>\n",
              "      <td>-0.093675</td>\n",
              "      <td>0.623150</td>\n",
              "      <td>-0.614754</td>\n",
              "      <td>0.073104</td>\n",
              "      <td>-0.467231</td>\n",
              "      <td>-0.773465</td>\n",
              "      <td>-0.761976</td>\n",
              "      <td>-0.262380</td>\n",
              "      <td>0.909204</td>\n",
              "      <td>0.017039</td>\n",
              "      <td>1.220186</td>\n",
              "      <td>1.799216</td>\n",
              "      <td>1.397674</td>\n",
              "      <td>2.207531</td>\n",
              "      <td>2.049861</td>\n",
              "      <td>0.404792</td>\n",
              "      <td>2.200704</td>\n",
              "      <td>-0.664651</td>\n",
              "      <td>0.958330</td>\n",
              "      <td>...</td>\n",
              "      <td>1.731633</td>\n",
              "      <td>1.814651</td>\n",
              "      <td>0.672942</td>\n",
              "      <td>1.581363</td>\n",
              "      <td>0.165341</td>\n",
              "      <td>0.358127</td>\n",
              "      <td>-0.583133</td>\n",
              "      <td>-0.222501</td>\n",
              "      <td>0.178766</td>\n",
              "      <td>-0.498480</td>\n",
              "      <td>0.579855</td>\n",
              "      <td>-0.143496</td>\n",
              "      <td>0.460771</td>\n",
              "      <td>-0.523263</td>\n",
              "      <td>-0.869717</td>\n",
              "      <td>1.096581</td>\n",
              "      <td>-0.852295</td>\n",
              "      <td>-0.539188</td>\n",
              "      <td>-1.188667</td>\n",
              "      <td>0.006937</td>\n",
              "      <td>0.744506</td>\n",
              "      <td>1.754389</td>\n",
              "      <td>1.170349</td>\n",
              "      <td>1.472925</td>\n",
              "      <td>-0.834385</td>\n",
              "      <td>-0.705218</td>\n",
              "      <td>0.598141</td>\n",
              "      <td>-0.475575</td>\n",
              "      <td>0.764645</td>\n",
              "      <td>0.481729</td>\n",
              "      <td>0.177472</td>\n",
              "      <td>0.751029</td>\n",
              "      <td>-0.546000</td>\n",
              "      <td>-0.652858</td>\n",
              "      <td>1.430395</td>\n",
              "      <td>2.211405</td>\n",
              "      <td>0.890957</td>\n",
              "      <td>0.238494</td>\n",
              "      <td>1.140568</td>\n",
              "      <td>0.228872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.136987</td>\n",
              "      <td>0.391177</td>\n",
              "      <td>1.662034</td>\n",
              "      <td>0.496431</td>\n",
              "      <td>0.327838</td>\n",
              "      <td>-1.019523</td>\n",
              "      <td>0.703860</td>\n",
              "      <td>0.978327</td>\n",
              "      <td>0.115359</td>\n",
              "      <td>-0.414599</td>\n",
              "      <td>0.405612</td>\n",
              "      <td>-0.298265</td>\n",
              "      <td>0.829553</td>\n",
              "      <td>-0.606347</td>\n",
              "      <td>-0.580319</td>\n",
              "      <td>-0.308852</td>\n",
              "      <td>1.083191</td>\n",
              "      <td>0.408381</td>\n",
              "      <td>0.829244</td>\n",
              "      <td>1.129986</td>\n",
              "      <td>-0.512760</td>\n",
              "      <td>-0.323033</td>\n",
              "      <td>-0.640646</td>\n",
              "      <td>0.558617</td>\n",
              "      <td>-0.699157</td>\n",
              "      <td>-0.590015</td>\n",
              "      <td>-0.699474</td>\n",
              "      <td>-0.151121</td>\n",
              "      <td>-0.085373</td>\n",
              "      <td>0.177244</td>\n",
              "      <td>-0.563481</td>\n",
              "      <td>-0.552638</td>\n",
              "      <td>0.490241</td>\n",
              "      <td>0.789883</td>\n",
              "      <td>1.422918</td>\n",
              "      <td>1.493045</td>\n",
              "      <td>-0.300187</td>\n",
              "      <td>-0.277215</td>\n",
              "      <td>-0.882102</td>\n",
              "      <td>-0.600840</td>\n",
              "      <td>...</td>\n",
              "      <td>1.087104</td>\n",
              "      <td>1.447307</td>\n",
              "      <td>0.089668</td>\n",
              "      <td>-0.076284</td>\n",
              "      <td>-0.540646</td>\n",
              "      <td>-0.473127</td>\n",
              "      <td>-0.145776</td>\n",
              "      <td>-2.068941</td>\n",
              "      <td>-1.029554</td>\n",
              "      <td>-1.087844</td>\n",
              "      <td>-0.986421</td>\n",
              "      <td>-1.754539</td>\n",
              "      <td>-0.388168</td>\n",
              "      <td>-0.651338</td>\n",
              "      <td>0.456621</td>\n",
              "      <td>-1.542705</td>\n",
              "      <td>-0.031945</td>\n",
              "      <td>-1.367026</td>\n",
              "      <td>1.402736</td>\n",
              "      <td>-0.718951</td>\n",
              "      <td>-0.165714</td>\n",
              "      <td>-0.003140</td>\n",
              "      <td>0.086305</td>\n",
              "      <td>-0.128736</td>\n",
              "      <td>1.082792</td>\n",
              "      <td>-0.890047</td>\n",
              "      <td>0.591032</td>\n",
              "      <td>-0.060478</td>\n",
              "      <td>0.225874</td>\n",
              "      <td>0.830467</td>\n",
              "      <td>0.487542</td>\n",
              "      <td>0.763281</td>\n",
              "      <td>1.424589</td>\n",
              "      <td>0.957192</td>\n",
              "      <td>0.505905</td>\n",
              "      <td>0.591134</td>\n",
              "      <td>0.148477</td>\n",
              "      <td>-0.077423</td>\n",
              "      <td>1.123010</td>\n",
              "      <td>0.899605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.057269</td>\n",
              "      <td>-1.272483</td>\n",
              "      <td>1.042172</td>\n",
              "      <td>0.293039</td>\n",
              "      <td>0.152190</td>\n",
              "      <td>0.489288</td>\n",
              "      <td>1.309904</td>\n",
              "      <td>-0.029723</td>\n",
              "      <td>0.527069</td>\n",
              "      <td>1.120779</td>\n",
              "      <td>-1.050842</td>\n",
              "      <td>0.219766</td>\n",
              "      <td>-0.193377</td>\n",
              "      <td>1.751008</td>\n",
              "      <td>-0.023067</td>\n",
              "      <td>1.201970</td>\n",
              "      <td>-1.209234</td>\n",
              "      <td>-0.256214</td>\n",
              "      <td>0.078142</td>\n",
              "      <td>0.065287</td>\n",
              "      <td>-1.358339</td>\n",
              "      <td>-1.020540</td>\n",
              "      <td>2.362678</td>\n",
              "      <td>1.541697</td>\n",
              "      <td>-0.139888</td>\n",
              "      <td>-0.272272</td>\n",
              "      <td>-0.332100</td>\n",
              "      <td>-0.212778</td>\n",
              "      <td>-1.032418</td>\n",
              "      <td>0.054423</td>\n",
              "      <td>0.349978</td>\n",
              "      <td>0.427400</td>\n",
              "      <td>-0.348927</td>\n",
              "      <td>0.405871</td>\n",
              "      <td>-0.972370</td>\n",
              "      <td>0.257894</td>\n",
              "      <td>0.288751</td>\n",
              "      <td>-0.164638</td>\n",
              "      <td>-0.159304</td>\n",
              "      <td>0.292241</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.211745</td>\n",
              "      <td>-0.317152</td>\n",
              "      <td>-1.183365</td>\n",
              "      <td>1.185431</td>\n",
              "      <td>-1.267223</td>\n",
              "      <td>0.453435</td>\n",
              "      <td>-1.451129</td>\n",
              "      <td>-0.684823</td>\n",
              "      <td>1.207672</td>\n",
              "      <td>3.182414</td>\n",
              "      <td>-0.670057</td>\n",
              "      <td>-0.930356</td>\n",
              "      <td>-0.494449</td>\n",
              "      <td>0.751487</td>\n",
              "      <td>-1.098554</td>\n",
              "      <td>-1.280458</td>\n",
              "      <td>-0.960031</td>\n",
              "      <td>-0.809254</td>\n",
              "      <td>1.316743</td>\n",
              "      <td>0.161259</td>\n",
              "      <td>0.763435</td>\n",
              "      <td>0.723464</td>\n",
              "      <td>-0.727163</td>\n",
              "      <td>-0.580504</td>\n",
              "      <td>-0.039703</td>\n",
              "      <td>-0.604332</td>\n",
              "      <td>0.729800</td>\n",
              "      <td>-0.104900</td>\n",
              "      <td>0.181665</td>\n",
              "      <td>1.259158</td>\n",
              "      <td>-1.701710</td>\n",
              "      <td>-0.943340</td>\n",
              "      <td>0.511244</td>\n",
              "      <td>0.617616</td>\n",
              "      <td>0.783032</td>\n",
              "      <td>0.423403</td>\n",
              "      <td>-0.914478</td>\n",
              "      <td>-0.468731</td>\n",
              "      <td>0.748034</td>\n",
              "      <td>1.250098</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 116 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       113       114       115\n",
              "0  0.903504 -1.379881  1.815419  ...  1.089321  0.030443  0.002744\n",
              "1 -1.005250 -0.774012  0.297203  ...  1.498940  1.809240  0.952663\n",
              "2 -0.570857  0.659692 -0.606319  ...  0.238494  1.140568  0.228872\n",
              "3  2.136987  0.391177  1.662034  ... -0.077423  1.123010  0.899605\n",
              "4 -1.057269 -1.272483  1.042172  ... -0.468731  0.748034  1.250098\n",
              "\n",
              "[5 rows x 116 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sfENy_lcvgo",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing aal Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9rvZrmuJX4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "f7f5cd95-ec5f-4fda-a089-14cc03f2fa02"
      },
      "source": [
        "sns.countplot(x = 'diag_Code', data=dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe5b69ebcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WONEKNfFSihk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "35b187d8-ab83-4773-cad7-439e4dcf7565"
      },
      "source": [
        "mean_readings = X.mean(axis=1)\n",
        "sns.distplot(mean_readings, rug=True, color= \"red\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe5b6925860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpTTcbbEShvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "7b19dcf5-7e76-40ce-dd4d-0b97262f429d"
      },
      "source": [
        "mean_feature = X.mean(axis=0)\n",
        "sns.distplot(mean_feature, rug=True, color= \"red\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe5b69257b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5fGeWRCTUXQ",
        "colab_type": "text"
      },
      "source": [
        "This shows aal parcellations reperesent left skewness in the fMRI Data\n",
        "\n",
        "This shows that negative values will contribute to the classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hBX4EB_TPJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "445eb55e-d01c-439b-9a4f-ebaf1b7734c9"
      },
      "source": [
        "median_readings = X.median(axis=1)\n",
        "sns.distplot(median_readings, rug=True, color= \"red\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe5b3b880f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR4kMl7tTO2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c8e272ea-45c6-4191-f627-6510e3328aff"
      },
      "source": [
        "median_feature = X.median(axis=0)\n",
        "sns.distplot(median_feature, rug=True, color= \"red\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe5b3acecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZCdjE2oc0Ci",
        "colab_type": "text"
      },
      "source": [
        "# Statistical Models on aal Dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okKht4_TVEWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.api as sta"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF0LI1ToVEFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afc05782-0bf5-41e3-c645-f95e066aa1bd"
      },
      "source": [
        "model = sta.OLS(y, X)\n",
        "\n",
        "results = model.fit()\n",
        "\n",
        "print(results.summary())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 OLS Regression Results                                \n",
            "=======================================================================================\n",
            "Dep. Variable:              diag_Code   R-squared (uncentered):                   0.446\n",
            "Model:                            OLS   Adj. R-squared (uncentered):             -8.638\n",
            "Method:                 Least Squares   F-statistic:                            0.04911\n",
            "Date:                Wed, 15 Jul 2020   Prob (F-statistic):                        1.00\n",
            "Time:                        18:28:16   Log-Likelihood:                         -66.072\n",
            "No. Observations:                  87   AIC:                                      296.1\n",
            "Df Residuals:                       5   BIC:                                      498.3\n",
            "Df Model:                          82                                                  \n",
            "Covariance Type:            nonrobust                                                  \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "0             -0.1674      0.465     -0.360      0.733      -1.362       1.027\n",
            "1             -0.1952      0.501     -0.390      0.713      -1.483       1.092\n",
            "2              0.1580      0.560      0.282      0.789      -1.281       1.597\n",
            "3             -0.0936      0.508     -0.184      0.861      -1.399       1.212\n",
            "4             -0.1515      0.463     -0.327      0.757      -1.342       1.039\n",
            "5              0.0957      0.646      0.148      0.888      -1.565       1.757\n",
            "6             -0.0392      0.501     -0.078      0.941      -1.326       1.248\n",
            "7             -0.0388      0.414     -0.094      0.929      -1.103       1.025\n",
            "8              0.0982      0.447      0.220      0.835      -1.050       1.246\n",
            "9             -0.0392      0.496     -0.079      0.940      -1.314       1.235\n",
            "10             0.0805      0.400      0.201      0.849      -0.948       1.109\n",
            "11            -0.0148      0.465     -0.032      0.976      -1.209       1.180\n",
            "12             0.1864      0.484      0.385      0.716      -1.059       1.432\n",
            "13             0.1127      0.429      0.263      0.803      -0.989       1.214\n",
            "14             0.0612      0.507      0.121      0.909      -1.242       1.365\n",
            "15            -0.1168      0.467     -0.250      0.812      -1.317       1.083\n",
            "16            -0.0244      0.630     -0.039      0.971      -1.645       1.596\n",
            "17            -0.0363      0.618     -0.059      0.955      -1.625       1.552\n",
            "18             0.0072      0.421      0.017      0.987      -1.074       1.089\n",
            "19             0.1257      0.436      0.289      0.784      -0.994       1.245\n",
            "20             0.1276      0.595      0.214      0.839      -1.402       1.658\n",
            "21            -0.0519      0.512     -0.101      0.923      -1.367       1.264\n",
            "22             0.0684      0.407      0.168      0.873      -0.977       1.114\n",
            "23            -0.0506      0.495     -0.102      0.923      -1.323       1.222\n",
            "24             0.0391      0.450      0.087      0.934      -1.118       1.196\n",
            "25             0.1332      0.514      0.259      0.806      -1.189       1.455\n",
            "26             0.2124      0.527      0.403      0.704      -1.142       1.567\n",
            "27             0.0161      0.549      0.029      0.978      -1.395       1.427\n",
            "28             0.0427      0.446      0.096      0.927      -1.104       1.190\n",
            "29            -0.0361      0.568     -0.064      0.952      -1.496       1.424\n",
            "30             0.0291      0.416      0.070      0.947      -1.040       1.098\n",
            "31            -0.0369      0.445     -0.083      0.937      -1.182       1.108\n",
            "32             0.1805      0.450      0.401      0.705      -0.975       1.336\n",
            "33            -0.0681      0.428     -0.159      0.880      -1.168       1.031\n",
            "34            -0.1283      0.475     -0.270      0.798      -1.349       1.093\n",
            "35            -0.1856      0.445     -0.417      0.694      -1.331       0.960\n",
            "36             0.1462      0.586      0.250      0.813      -1.359       1.651\n",
            "37             0.0304      0.545      0.056      0.958      -1.371       1.432\n",
            "38             0.1074      0.483      0.222      0.833      -1.133       1.348\n",
            "39            -0.1205      0.452     -0.266      0.801      -1.283       1.042\n",
            "40             0.0087      0.424      0.020      0.985      -1.082       1.100\n",
            "41             0.0819      0.427      0.192      0.855      -1.015       1.178\n",
            "42             0.0712      0.406      0.175      0.868      -0.972       1.115\n",
            "43             0.0626      0.435      0.144      0.891      -1.056       1.182\n",
            "44             0.1318      0.474      0.278      0.792      -1.086       1.350\n",
            "45             0.0744      0.581      0.128      0.903      -1.419       1.568\n",
            "46            -0.0727      0.473     -0.154      0.884      -1.288       1.142\n",
            "47            -0.1069      0.429     -0.249      0.813      -1.209       0.995\n",
            "48             0.0420      0.507      0.083      0.937      -1.260       1.344\n",
            "49             0.2211      0.520      0.425      0.688      -1.116       1.558\n",
            "50            -0.0963      0.591     -0.163      0.877      -1.615       1.422\n",
            "51             0.0211      0.416      0.051      0.961      -1.047       1.090\n",
            "52            -0.1399      0.456     -0.307      0.772      -1.313       1.033\n",
            "53             0.1666      0.430      0.388      0.714      -0.939       1.272\n",
            "54            -0.0405      0.511     -0.079      0.940      -1.355       1.274\n",
            "55            -0.1495      0.484     -0.309      0.770      -1.394       1.095\n",
            "56             0.2027      0.461      0.440      0.679      -0.983       1.388\n",
            "57             0.0930      0.362      0.257      0.807      -0.837       1.023\n",
            "58            -0.0651      0.370     -0.176      0.867      -1.016       0.886\n",
            "59             0.0230      0.453      0.051      0.961      -1.141       1.187\n",
            "60             0.0113      0.442      0.025      0.981      -1.124       1.147\n",
            "61            -0.0920      0.466     -0.197      0.851      -1.290       1.107\n",
            "62             0.0179      0.461      0.039      0.971      -1.167       1.203\n",
            "63             0.1352      0.460      0.294      0.781      -1.049       1.319\n",
            "64            -0.1025      0.491     -0.209      0.843      -1.364       1.159\n",
            "65            -0.0459      0.505     -0.091      0.931      -1.344       1.253\n",
            "66             0.1586      0.567      0.280      0.791      -1.298       1.615\n",
            "67            -0.1078      0.531     -0.203      0.847      -1.473       1.257\n",
            "68            -0.2049      0.521     -0.393      0.710      -1.544       1.134\n",
            "69             0.0746      0.506      0.148      0.888      -1.225       1.374\n",
            "70            -0.0660      0.593     -0.111      0.916      -1.590       1.458\n",
            "71             0.0286      0.537      0.053      0.960      -1.351       1.408\n",
            "72            -0.0928      0.480     -0.193      0.854      -1.328       1.142\n",
            "73             0.1862      0.585      0.318      0.763      -1.317       1.689\n",
            "74            -0.0684      0.407     -0.168      0.873      -1.114       0.977\n",
            "75             0.0536      0.426      0.126      0.905      -1.042       1.149\n",
            "76             0.0584      0.402      0.145      0.890      -0.974       1.091\n",
            "77             0.1463      0.489      0.299      0.777      -1.111       1.404\n",
            "78            -0.0023      0.476     -0.005      0.996      -1.226       1.221\n",
            "79            -0.0453      0.437     -0.104      0.922      -1.169       1.079\n",
            "80             0.1108      0.661      0.168      0.873      -1.589       1.810\n",
            "81             0.0254      0.594      0.043      0.967      -1.501       1.552\n",
            "82            -0.2093      0.387     -0.541      0.612      -1.203       0.785\n",
            "83            -0.0026      0.434     -0.006      0.996      -1.117       1.112\n",
            "84            -0.1086      0.415     -0.262      0.804      -1.175       0.958\n",
            "85             0.1162      0.492      0.236      0.823      -1.149       1.382\n",
            "86            -0.0604      0.497     -0.121      0.908      -1.338       1.218\n",
            "87            -0.0367      0.466     -0.079      0.940      -1.235       1.162\n",
            "88             0.0615      0.444      0.138      0.895      -1.081       1.204\n",
            "89             0.0891      0.496      0.180      0.865      -1.186       1.364\n",
            "90             0.0043      0.450      0.010      0.993      -1.152       1.161\n",
            "91             0.1308      0.511      0.256      0.808      -1.183       1.445\n",
            "92             0.1055      0.658      0.160      0.879      -1.585       1.796\n",
            "93            -0.0379      0.603     -0.063      0.952      -1.588       1.512\n",
            "94            -0.0002      0.463     -0.000      1.000      -1.191       1.190\n",
            "95            -0.0944      0.398     -0.237      0.822      -1.118       0.929\n",
            "96             0.0512      0.475      0.108      0.918      -1.170       1.273\n",
            "97            -0.0436      0.343     -0.127      0.904      -0.926       0.839\n",
            "98            -0.0004      0.525     -0.001      0.999      -1.350       1.349\n",
            "99             0.0173      0.456      0.038      0.971      -1.156       1.191\n",
            "100           -0.0783      0.509     -0.154      0.884      -1.386       1.230\n",
            "101            0.0328      0.460      0.071      0.946      -1.151       1.216\n",
            "102            0.0167      0.517      0.032      0.976      -1.311       1.345\n",
            "103           -0.0149      0.532     -0.028      0.979      -1.383       1.353\n",
            "104            0.1160      0.451      0.257      0.807      -1.044       1.277\n",
            "105            0.0171      0.429      0.040      0.970      -1.086       1.120\n",
            "106            0.0751      0.540      0.139      0.895      -1.312       1.463\n",
            "107            0.0338      0.433      0.078      0.941      -1.079       1.146\n",
            "108            0.0335      0.438      0.077      0.942      -1.092       1.159\n",
            "109            0.1562      0.548      0.285      0.787      -1.254       1.566\n",
            "110           -0.0044      0.495     -0.009      0.993      -1.276       1.267\n",
            "111           -0.0319      0.593     -0.054      0.959      -1.555       1.491\n",
            "112            0.0697      0.467      0.149      0.887      -1.131       1.271\n",
            "113            0.0141      0.641      0.022      0.983      -1.633       1.661\n",
            "114           -0.2160      0.554     -0.390      0.713      -1.640       1.208\n",
            "115            0.1461      0.476      0.307      0.771      -1.078       1.370\n",
            "==============================================================================\n",
            "Omnibus:                        5.995   Durbin-Watson:                   0.203\n",
            "Prob(Omnibus):                  0.050   Jarque-Bera (JB):                5.574\n",
            "Skew:                          -0.613   Prob(JB):                       0.0616\n",
            "Kurtosis:                       3.180   Cond. No.                     1.23e+16\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The input rank is higher than the number of observations.\n",
            "[3] The smallest eigenvalue is 9.62e-30. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIoVetN3Warz",
        "colab_type": "text"
      },
      "source": [
        "R-squared value is 0.446 and Adjusted R-squared is -ve, this means that a lot of the features are unimportant. \n",
        "\n",
        "We also understand that the features have explained very less variability. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_1MmeQJYy1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA,KernelPCA, FactorAnalysis, DictionaryLearning"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w43Tj1rtY2d4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca_SBD = PCA(n_components=4)\n",
        "principalComponents = pca_SBD.fit_transform(X)\n",
        "pca_df = pd.DataFrame(principalComponents, columns=['PC1', 'PC2', 'PC3', 'PC4'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02InLWKkY2Q2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "d7189ed4-cc39-4e70-d48f-f99d2eae5894"
      },
      "source": [
        "model = sta.OLS(y, pca_df.values)\n",
        "\n",
        "results = model.fit()\n",
        "\n",
        "print(results.summary())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 OLS Regression Results                                \n",
            "=======================================================================================\n",
            "Dep. Variable:              diag_Code   R-squared (uncentered):                   0.065\n",
            "Model:                            OLS   Adj. R-squared (uncentered):              0.020\n",
            "Method:                 Least Squares   F-statistic:                              1.452\n",
            "Date:                Wed, 15 Jul 2020   Prob (F-statistic):                       0.224\n",
            "Time:                        18:28:22   Log-Likelihood:                         -88.827\n",
            "No. Observations:                  87   AIC:                                      185.7\n",
            "Df Residuals:                      83   BIC:                                      195.5\n",
            "Df Model:                           4                                                  \n",
            "Covariance Type:            nonrobust                                                  \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "x1            -0.0019      0.018     -0.103      0.918      -0.038       0.034\n",
            "x2            -0.0337      0.024     -1.398      0.166      -0.082       0.014\n",
            "x3            -0.0041      0.027     -0.155      0.878      -0.057       0.049\n",
            "x4            -0.0528      0.027     -1.954      0.054      -0.107       0.001\n",
            "==============================================================================\n",
            "Omnibus:                      208.217   Durbin-Watson:                   0.137\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                8.583\n",
            "Skew:                          -0.026   Prob(JB):                       0.0137\n",
            "Kurtosis:                       1.462   Cond. No.                         1.50\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTE9Gqa5VEDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "aab179cb-9b7b-4157-86af-d070dc229721"
      },
      "source": [
        "pca_SBD = PCA(0.9)\n",
        "principalComponents = pca_SBD.fit_transform(X)\n",
        "pca_df = pd.DataFrame(principalComponents)\n",
        "print(pca_df.shape)\n",
        "\n",
        "model = sta.OLS(y, pca_df.values[:,:10]) \n",
        "\n",
        "## using OLS on first 10 features Principal components only explain 10.2 % data variability\n",
        "\n",
        "results = model.fit()\n",
        "\n",
        "print(results.summary())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(87, 35)\n",
            "                                 OLS Regression Results                                \n",
            "=======================================================================================\n",
            "Dep. Variable:              diag_Code   R-squared (uncentered):                   0.092\n",
            "Model:                            OLS   Adj. R-squared (uncentered):             -0.026\n",
            "Method:                 Least Squares   F-statistic:                             0.7768\n",
            "Date:                Wed, 15 Jul 2020   Prob (F-statistic):                       0.651\n",
            "Time:                        18:28:24   Log-Likelihood:                         -87.589\n",
            "No. Observations:                  87   AIC:                                      195.2\n",
            "Df Residuals:                      77   BIC:                                      219.8\n",
            "Df Model:                          10                                                  \n",
            "Covariance Type:            nonrobust                                                  \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "x1            -0.0019      0.018     -0.101      0.920      -0.039       0.035\n",
            "x2            -0.0337      0.025     -1.366      0.176      -0.083       0.015\n",
            "x3            -0.0041      0.027     -0.151      0.880      -0.058       0.050\n",
            "x4            -0.0528      0.028     -1.909      0.060      -0.108       0.002\n",
            "x5            -0.0068      0.030     -0.229      0.819      -0.066       0.053\n",
            "x6             0.0103      0.033      0.311      0.757      -0.056       0.076\n",
            "x7            -0.0019      0.034     -0.055      0.956      -0.069       0.065\n",
            "x8            -0.0198      0.038     -0.517      0.607      -0.096       0.057\n",
            "x9             0.0314      0.040      0.788      0.433      -0.048       0.111\n",
            "x10            0.0447      0.041      1.088      0.280      -0.037       0.126\n",
            "==============================================================================\n",
            "Omnibus:                       55.184   Durbin-Watson:                   0.206\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                6.679\n",
            "Skew:                          -0.088   Prob(JB):                       0.0355\n",
            "Kurtosis:                       1.654   Cond. No.                         2.22\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCb4ZfLPbA-9",
        "colab_type": "text"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2DBMtdebbP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdHba51BvGR3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4111b96c-5758-401a-f25d-14846ff839c3"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHgazYjScD_y",
        "colab_type": "text"
      },
      "source": [
        "# Linear and Logistic Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WswXdKU0bZzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "18c8eb3f-8271-48b6-9b06-99db484f5e21"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression, LinearRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import r2_score,classification_report, accuracy_score, roc_curve, roc_auc_score, auc\n",
        "\n",
        "lr = LinearRegression()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "\n",
        "\n",
        "lr = LogisticRegression()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "lr = LogisticRegressionCV()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
            "[[2 6]\n",
            " [3 7]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.40      0.25      0.31         8\n",
            "Bipolar Disorder       0.54      0.70      0.61        10\n",
            "\n",
            "        accuracy                           0.50        18\n",
            "       macro avg       0.47      0.47      0.46        18\n",
            "    weighted avg       0.48      0.50      0.47        18\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "\n",
            " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "[[5 3]\n",
            " [6 4]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.45      0.62      0.53         8\n",
            "Bipolar Disorder       0.57      0.40      0.47        10\n",
            "\n",
            "        accuracy                           0.50        18\n",
            "       macro avg       0.51      0.51      0.50        18\n",
            "    weighted avg       0.52      0.50      0.50        18\n",
            "\n",
            "Accuracy Score:  0.5\n",
            "\n",
            "\n",
            " LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
            "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
            "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
            "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
            "                     solver='lbfgs', tol=0.0001, verbose=0)\n",
            "[[6 2]\n",
            " [5 5]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.55      0.75      0.63         8\n",
            "Bipolar Disorder       0.71      0.50      0.59        10\n",
            "\n",
            "        accuracy                           0.61        18\n",
            "       macro avg       0.63      0.62      0.61        18\n",
            "    weighted avg       0.64      0.61      0.61        18\n",
            "\n",
            "Accuracy Score:  0.6111111111111112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75rI5T7mcAHO",
        "colab_type": "text"
      },
      "source": [
        "# Tree Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKv84Y05bzvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1fc5dcd-90c7-49b6-db9a-16107a22363e"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "clf = dt.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "clf = rf.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "lr = GradientBoostingClassifier()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
            "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
            "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
            "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
            "                     solver='lbfgs', tol=0.0001, verbose=0)\n",
            "[[2 6]\n",
            " [6 4]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.25      0.25      0.25         8\n",
            "Bipolar Disorder       0.40      0.40      0.40        10\n",
            "\n",
            "        accuracy                           0.33        18\n",
            "       macro avg       0.33      0.33      0.33        18\n",
            "    weighted avg       0.33      0.33      0.33        18\n",
            "\n",
            "Accuracy Score:  0.3333333333333333\n",
            "\n",
            "\n",
            " LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
            "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
            "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
            "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
            "                     solver='lbfgs', tol=0.0001, verbose=0)\n",
            "[[3 5]\n",
            " [6 4]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.33      0.38      0.35         8\n",
            "Bipolar Disorder       0.44      0.40      0.42        10\n",
            "\n",
            "        accuracy                           0.39        18\n",
            "       macro avg       0.39      0.39      0.39        18\n",
            "    weighted avg       0.40      0.39      0.39        18\n",
            "\n",
            "Accuracy Score:  0.3888888888888889\n",
            "\n",
            "\n",
            " GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "[[3 5]\n",
            " [6 4]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.33      0.38      0.35         8\n",
            "Bipolar Disorder       0.44      0.40      0.42        10\n",
            "\n",
            "        accuracy                           0.39        18\n",
            "       macro avg       0.39      0.39      0.39        18\n",
            "    weighted avg       0.40      0.39      0.39        18\n",
            "\n",
            "Accuracy Score:  0.3888888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qgdYfbWcTL8",
        "colab_type": "text"
      },
      "source": [
        "# Clustering Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPX0dJavbztH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "22eaa830-bedc-43ad-f925-82ba00db3e38"
      },
      "source": [
        "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
        "\n",
        "lr = KMeans()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "lr = AgglomerativeClustering()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "y_hat = clf.fit_predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "lr = SpectralClustering()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "y_hat = clf.fit_predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print('Accuracy Score: ',accuracy_score(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
            "       n_clusters=8, n_init=10, n_jobs=None, precompute_distances='auto',\n",
            "       random_state=None, tol=0.0001, verbose=0)\n",
            "[[1 7]\n",
            " [1 9]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.50      0.12      0.20         8\n",
            "Bipolar Disorder       0.56      0.90      0.69        10\n",
            "\n",
            "        accuracy                           0.56        18\n",
            "       macro avg       0.53      0.51      0.45        18\n",
            "    weighted avg       0.53      0.56      0.47        18\n",
            "\n",
            "Accuracy Score:  0.5555555555555556\n",
            "\n",
            "\n",
            " AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
            "                        connectivity=None, distance_threshold=None,\n",
            "                        linkage='ward', memory=None, n_clusters=2)\n",
            "[[6 2]\n",
            " [6 4]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.50      0.75      0.60         8\n",
            "Bipolar Disorder       0.67      0.40      0.50        10\n",
            "\n",
            "        accuracy                           0.56        18\n",
            "       macro avg       0.58      0.57      0.55        18\n",
            "    weighted avg       0.59      0.56      0.54        18\n",
            "\n",
            "Accuracy Score:  0.5555555555555556\n",
            "\n",
            "\n",
            " SpectralClustering(affinity='rbf', assign_labels='kmeans', coef0=1, degree=3,\n",
            "                   eigen_solver=None, eigen_tol=0.0, gamma=1.0,\n",
            "                   kernel_params=None, n_clusters=8, n_components=None,\n",
            "                   n_init=10, n_jobs=None, n_neighbors=10, random_state=None)\n",
            "[[7 1]\n",
            " [9 1]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.44      0.88      0.58         8\n",
            "Bipolar Disorder       0.50      0.10      0.17        10\n",
            "\n",
            "        accuracy                           0.44        18\n",
            "       macro avg       0.47      0.49      0.38        18\n",
            "    weighted avg       0.47      0.44      0.35        18\n",
            "\n",
            "Accuracy Score:  0.4444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNdzO8a5cWX7",
        "colab_type": "text"
      },
      "source": [
        "# KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyh7FVBpbzY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e79f2909-e134-4639-9537-49de3657137b"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "lr = KNeighborsClassifier()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "y_hat = clf.predict(X_test)\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n",
        "y_hat = y_hat > 0\n",
        "print('\\n\\n',str(lr))\n",
        "print(confusion_matrix(y_test, y_hat))\n",
        "print(classification_report(y_test, y_hat, target_names=names))\n",
        "print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "[[2 6]\n",
            " [6 4]]\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "   Schizophrenia       0.25      0.25      0.25         8\n",
            "Bipolar Disorder       0.40      0.40      0.40        10\n",
            "\n",
            "        accuracy                           0.33        18\n",
            "       macro avg       0.33      0.33      0.33        18\n",
            "    weighted avg       0.33      0.33      0.33        18\n",
            "\n",
            "KNeighborsClassifier Accuracy Score:  0.3333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hFiLs-nccjM",
        "colab_type": "text"
      },
      "source": [
        "# Performing regression analysis and Classification on other parcellations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3274pWOLZjM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression, LinearRegression, LogisticRegressionCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "names = ['Schizophrenia','Bipolar Disorder']\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIZcKSNuswXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "b511f48f-e996-4b37-fb75-0832e795009b"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([0, 0, 0, 1, 1, 1])\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)\n",
        "print(sss.get_n_splits(X, y))\n",
        "\n",
        "print(sss)\n",
        "\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "    print(train_index)\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    print(X_train.shape, y_train.shape)\n",
        "    print(X_test.shape, y_test.shape)\n",
        "\n",
        "\n",
        "    lr = LinearRegression()\n",
        "    clf = lr.fit(X_train, y_train)\n",
        "    y_hat = clf.predict(X_test)\n",
        "    y_hat = y_hat > 0\n",
        "    model_names.append(lr.__class__.__name__)\n",
        "    accuracy.append(accuracy_score(y_test, y_hat))\n",
        "    print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.5,\n",
            "            train_size=None)\n",
            "[5 2 3]\n",
            "TRAIN: [5 2 3] TEST: [4 1 0]\n",
            "(3, 2) (3,)\n",
            "(3, 2) (3,)\n",
            "LinearRegression Accuracy Score:  0.3333333333333333\n",
            "[5 1 4]\n",
            "TRAIN: [5 1 4] TEST: [0 2 3]\n",
            "(3, 2) (3,)\n",
            "(3, 2) (3,)\n",
            "LinearRegression Accuracy Score:  0.3333333333333333\n",
            "[5 0 2]\n",
            "TRAIN: [5 0 2] TEST: [4 3 1]\n",
            "(3, 2) (3,)\n",
            "(3, 2) (3,)\n",
            "LinearRegression Accuracy Score:  0.3333333333333333\n",
            "[4 1 0]\n",
            "TRAIN: [4 1 0] TEST: [2 3 5]\n",
            "(3, 2) (3,)\n",
            "(3, 2) (3,)\n",
            "LinearRegression Accuracy Score:  0.0\n",
            "[0 5 1]\n",
            "TRAIN: [0 5 1] TEST: [3 4 2]\n",
            "(3, 2) (3,)\n",
            "(3, 2) (3,)\n",
            "LinearRegression Accuracy Score:  0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJmcY-TKbzWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb8024bd-f655-4866-f464-71d740f3a8e5"
      },
      "source": [
        "model_names = list()\n",
        "accuracy = list()\n",
        "\n",
        "for i, nm in enumerate(df):\n",
        "  if i > 13:\n",
        "    pass\n",
        "  else:\n",
        "    print(i, nm)\n",
        "    X = df.get(nm)\n",
        "    y = np.array(df.get('diag_Code'))\n",
        "    print(X.shape, y.shape)\n",
        "    X = np.array(X)\n",
        "\n",
        "    # Strafied Shuffle Split\n",
        "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.5, random_state=0)\n",
        "\n",
        "    for train_index, test_index in sss.split(X, y):\n",
        "      sss.get_n_splits()\n",
        "      print(\"TRAIN:\", train_index[1:5], \"TEST:\", test_index[1:5])\n",
        "      X_train, X_test = X[:][train_index], X[:][test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "      print(X_train.shape, y_train.shape)\n",
        "      print(X_test.shape, y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "      lr = LinearRegression()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = LogisticRegression()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = LogisticRegressionCV()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = DecisionTreeClassifier()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = RandomForestClassifier()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = GradientBoostingClassifier()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = KMeans()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = AgglomerativeClustering()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.fit_predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = SpectralClustering()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.fit_predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "\n",
        "      lr = KNeighborsClassifier()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 aal\n",
            "(87, 116) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.4318181818181818\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.4772727272727273\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5909090909090909\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4318181818181818\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.45454545454545453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.4318181818181818\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.3409090909090909\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5227272727272727\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.4090909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.4090909090909091\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 116) (43,)\n",
            "(44, 116) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "1 harvard_sub_25\n",
            "(87, 22) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.4772727272727273\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.45454545454545453\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.38636363636363635\n",
            "GradientBoostingClassifier Accuracy Score:  0.4090909090909091\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4318181818181818\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.4772727272727273\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "GradientBoostingClassifier Accuracy Score:  0.45454545454545453\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.5681818181818182\n",
            "KNeighborsClassifier Accuracy Score:  0.45454545454545453\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.45454545454545453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "GradientBoostingClassifier Accuracy Score:  0.4772727272727273\n",
            "KMeans Accuracy Score:  0.5454545454545454\n",
            "AgglomerativeClustering Accuracy Score:  0.38636363636363635\n",
            "SpectralClustering Accuracy Score:  0.36363636363636365\n",
            "KNeighborsClassifier Accuracy Score:  0.5\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.4318181818181818\n",
            "LogisticRegression Accuracy Score:  0.45454545454545453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "GradientBoostingClassifier Accuracy Score:  0.4318181818181818\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.38636363636363635\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.4090909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.36363636363636365\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.45454545454545453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.4318181818181818\n",
            "GradientBoostingClassifier Accuracy Score:  0.36363636363636365\n",
            "KMeans Accuracy Score:  0.5909090909090909\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.4318181818181818\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.4090909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "GradientBoostingClassifier Accuracy Score:  0.38636363636363635\n",
            "KMeans Accuracy Score:  0.5681818181818182\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.4090909090909091\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.38636363636363635\n",
            "GradientBoostingClassifier Accuracy Score:  0.4318181818181818\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.4318181818181818\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.36363636363636365\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 22) (43,)\n",
            "(44, 22) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "2 harvard_cort_25\n",
            "(87, 96) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.38636363636363635\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.6818181818181818\n",
            "SpectralClustering Accuracy Score:  0.6136363636363636\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.36363636363636365\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.6590909090909091\n",
            "KMeans Accuracy Score:  0.4090909090909091\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.75\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.75\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.8181818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.6590909090909091\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6818181818181818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.3181818181818182\n",
            "AgglomerativeClustering Accuracy Score:  0.25\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.4772727272727273\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 96) (43,)\n",
            "(44, 96) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.7045454545454546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.6818181818181818\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.7045454545454546\n",
            "3 destrieux\n",
            "(87, 148) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.5909090909090909\n",
            "LogisticRegression Accuracy Score:  0.7272727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.5681818181818182\n",
            "AgglomerativeClustering Accuracy Score:  0.4318181818181818\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.4318181818181818\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.6363636363636364\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.7272727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.6136363636363636\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.4318181818181818\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.6818181818181818\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.6136363636363636\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.6590909090909091\n",
            "KMeans Accuracy Score:  0.4090909090909091\n",
            "AgglomerativeClustering Accuracy Score:  0.5909090909090909\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.7272727272727273\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.6136363636363636\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.3181818181818182\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.6136363636363636\n",
            "LogisticRegression Accuracy Score:  0.7045454545454546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "GradientBoostingClassifier Accuracy Score:  0.6818181818181818\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 148) (43,)\n",
            "(44, 148) (44,)\n",
            "LinearRegression Accuracy Score:  0.6136363636363636\n",
            "LogisticRegression Accuracy Score:  0.7272727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "4 yeo\n",
            "(87, 17) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.6590909090909091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.6590909090909091\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "GradientBoostingClassifier Accuracy Score:  0.7272727272727273\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.5909090909090909\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.38636363636363635\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.5909090909090909\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.7045454545454546\n",
            "KMeans Accuracy Score:  0.5454545454545454\n",
            "AgglomerativeClustering Accuracy Score:  0.5909090909090909\n",
            "SpectralClustering Accuracy Score:  0.38636363636363635\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.7272727272727273\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.5909090909090909\n",
            "AgglomerativeClustering Accuracy Score:  0.36363636363636365\n",
            "SpectralClustering Accuracy Score:  0.5909090909090909\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 17) (43,)\n",
            "(44, 17) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "5 basc_multiscale_122\n",
            "(87, 122) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.4318181818181818\n",
            "KMeans Accuracy Score:  0.5454545454545454\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.4772727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.4772727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.6363636363636364\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "GradientBoostingClassifier Accuracy Score:  0.45454545454545453\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "GradientBoostingClassifier Accuracy Score:  0.5227272727272727\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.5227272727272727\n",
            "KMeans Accuracy Score:  0.4318181818181818\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 122) (43,)\n",
            "(44, 122) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "GradientBoostingClassifier Accuracy Score:  0.6818181818181818\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.3409090909090909\n",
            "KNeighborsClassifier Accuracy Score:  0.75\n",
            "6 basc_multiscale_197\n",
            "(87, 197) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.5909090909090909\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.4772727272727273\n",
            "KMeans Accuracy Score:  0.5454545454545454\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.4090909090909091\n",
            "LogisticRegression Accuracy Score:  0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.4772727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.4090909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.45454545454545453\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.4318181818181818\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.4318181818181818\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.38636363636363635\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.45454545454545453\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 197) (43,)\n",
            "(44, 197) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.36363636363636365\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "7 basc_multiscale_325\n",
            "(87, 325) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.6818181818181818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "LogisticRegressionCV Accuracy Score:  0.38636363636363635\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.38636363636363635\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.5681818181818182\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.4772727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.4090909090909091\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.5909090909090909\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.6590909090909091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 325) (43,)\n",
            "(44, 325) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.6590909090909091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.7272727272727273\n",
            "8 basc_multiscale_444\n",
            "(87, 444) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.6818181818181818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.4090909090909091\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.7272727272727273\n",
            "SpectralClustering Accuracy Score:  0.5681818181818182\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5227272727272727\n",
            "KMeans Accuracy Score:  0.4318181818181818\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.7272727272727273\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.5681818181818182\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.7045454545454546\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5227272727272727\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 444) (43,)\n",
            "(44, 444) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.7954545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.4772727272727273\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: overflow encountered in square\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:322: RuntimeWarning: invalid value encountered in subtract\n",
            "  max_iter=max_iter, verbose=verbose)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py:304: RuntimeWarning: invalid value encountered in add\n",
            "  distances += XX\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:324: RuntimeWarning: overflow encountered in square\n",
            "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.6818181818181818\n",
            "9 power\n",
            "(87, 264) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.45454545454545453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.5\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "GradientBoostingClassifier Accuracy Score:  0.4318181818181818\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6818181818181818\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.5681818181818182\n",
            "AgglomerativeClustering Accuracy Score:  0.4318181818181818\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.45454545454545453\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.5227272727272727\n",
            "KMeans Accuracy Score:  0.4090909090909091\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.4318181818181818\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.6136363636363636\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.4772727272727273\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5227272727272727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.4318181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5227272727272727\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 264) (43,)\n",
            "(44, 264) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4318181818181818\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "10 dosenbach\n",
            "(87, 160) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.7272727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.6590909090909091\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "GradientBoostingClassifier Accuracy Score:  0.6818181818181818\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.6818181818181818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "LogisticRegressionCV Accuracy Score:  0.4318181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5227272727272727\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.7045454545454546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.6590909090909091\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.6136363636363636\n",
            "LogisticRegression Accuracy Score:  0.7272727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "GradientBoostingClassifier Accuracy Score:  0.6818181818181818\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5909090909090909\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.7045454545454546\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6818181818181818\n",
            "GradientBoostingClassifier Accuracy Score:  0.4772727272727273\n",
            "KMeans Accuracy Score:  0.4090909090909091\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.7045454545454546\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.7045454545454546\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.7272727272727273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.6818181818181818\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 160) (43,)\n",
            "(44, 160) (44,)\n",
            "LinearRegression Accuracy Score:  0.5909090909090909\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "11 smith20\n",
            "(87, 20) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.3181818181818182\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.4090909090909091\n",
            "LogisticRegression Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.4318181818181818\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "GradientBoostingClassifier Accuracy Score:  0.45454545454545453\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4090909090909091\n",
            "SpectralClustering Accuracy Score:  0.38636363636363635\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.4090909090909091\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.4318181818181818\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6818181818181818\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.6818181818181818\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.4318181818181818\n",
            "KNeighborsClassifier Accuracy Score:  0.6818181818181818\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.6818181818181818\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.5681818181818182\n",
            "SpectralClustering Accuracy Score:  0.4318181818181818\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.6136363636363636\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "GradientBoostingClassifier Accuracy Score:  0.7045454545454546\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.5909090909090909\n",
            "KNeighborsClassifier Accuracy Score:  0.75\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5227272727272727\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 20) (43,)\n",
            "(44, 20) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.6590909090909091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.75\n",
            "GradientBoostingClassifier Accuracy Score:  0.7727272727272727\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5909090909090909\n",
            "SpectralClustering Accuracy Score:  0.3181818181818182\n",
            "KNeighborsClassifier Accuracy Score:  0.75\n",
            "12 msdl\n",
            "(87, 39) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.5909090909090909\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.4318181818181818\n",
            "KMeans Accuracy Score:  0.5681818181818182\n",
            "AgglomerativeClustering Accuracy Score:  0.5909090909090909\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.38636363636363635\n",
            "LogisticRegression Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.45454545454545453\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.4090909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.38636363636363635\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.6818181818181818\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4318181818181818\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.4318181818181818\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.4318181818181818\n",
            "AgglomerativeClustering Accuracy Score:  0.4318181818181818\n",
            "SpectralClustering Accuracy Score:  0.6818181818181818\n",
            "KNeighborsClassifier Accuracy Score:  0.4090909090909091\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5227272727272727\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.4318181818181818\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.4090909090909091\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.7045454545454546\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5454545454545454\n",
            "SpectralClustering Accuracy Score:  0.4318181818181818\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.45454545454545453\n",
            "LogisticRegression Accuracy Score:  0.4090909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.45454545454545453\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.4318181818181818\n",
            "GradientBoostingClassifier Accuracy Score:  0.45454545454545453\n",
            "KMeans Accuracy Score:  0.3409090909090909\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4318181818181818\n",
            "KNeighborsClassifier Accuracy Score:  0.4318181818181818\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "GradientBoostingClassifier Accuracy Score:  0.7045454545454546\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.4772727272727273\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.4772727272727273\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 39) (43,)\n",
            "(44, 39) (44,)\n",
            "LinearRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.6818181818181818\n",
            "KMeans Accuracy Score:  0.36363636363636365\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "13 smith70\n",
            "(87, 70) (87,)\n",
            "TRAIN: [37 40 48 28] TEST: [ 0  7 35 80]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.5\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4090909090909091\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [ 2 34 10 37] TEST: [30 81 63 55]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "GradientBoostingClassifier Accuracy Score:  0.5681818181818182\n",
            "KMeans Accuracy Score:  0.45454545454545453\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.5454545454545454\n",
            "TRAIN: [27 10 77 29] TEST: [ 4 58 18 20]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.38636363636363635\n",
            "KNeighborsClassifier Accuracy Score:  0.5681818181818182\n",
            "TRAIN: [39 58 43 19] TEST: [41 24 13 20]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.4772727272727273\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.7727272727272727\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.4772727272727273\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.5454545454545454\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [57 34 58 75] TEST: [72 38 77 20]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.5909090909090909\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6363636363636364\n",
            "GradientBoostingClassifier Accuracy Score:  0.6136363636363636\n",
            "KMeans Accuracy Score:  0.5681818181818182\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.5909090909090909\n",
            "TRAIN: [ 2 48 57 66] TEST: [23  0 81 13]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegression Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.4318181818181818\n",
            "AgglomerativeClustering Accuracy Score:  0.6136363636363636\n",
            "SpectralClustering Accuracy Score:  0.45454545454545453\n",
            "KNeighborsClassifier Accuracy Score:  0.4772727272727273\n",
            "TRAIN: [59 69 46 47] TEST: [29  1 42  3]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.5227272727272727\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.7727272727272727\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.4318181818181818\n",
            "AgglomerativeClustering Accuracy Score:  0.5227272727272727\n",
            "SpectralClustering Accuracy Score:  0.5227272727272727\n",
            "KNeighborsClassifier Accuracy Score:  0.6590909090909091\n",
            "TRAIN: [52 60 30 10] TEST: [73 11 48 20]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.5454545454545454\n",
            "LogisticRegressionCV Accuracy Score:  0.5909090909090909\n",
            "LogisticRegressionCV Accuracy Score:  0.7272727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.75\n",
            "GradientBoostingClassifier Accuracy Score:  0.6363636363636364\n",
            "KMeans Accuracy Score:  0.5\n",
            "AgglomerativeClustering Accuracy Score:  0.6818181818181818\n",
            "SpectralClustering Accuracy Score:  0.5\n",
            "KNeighborsClassifier Accuracy Score:  0.6818181818181818\n",
            "TRAIN: [57  6 14  7] TEST: [36 64 23 13]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.5227272727272727\n",
            "LogisticRegression Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.6590909090909091\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "LogisticRegressionCV Accuracy Score:  0.5681818181818182\n",
            "GradientBoostingClassifier Accuracy Score:  0.5909090909090909\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.45454545454545453\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.6363636363636364\n",
            "TRAIN: [44 78  0 23] TEST: [58 38 25 71]\n",
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n",
            "LinearRegression Accuracy Score:  0.6363636363636364\n",
            "LogisticRegression Accuracy Score:  0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:296: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
            "  ).fit(X, sample_weight=sample_weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegressionCV Accuracy Score:  0.75\n",
            "LogisticRegressionCV Accuracy Score:  0.4772727272727273\n",
            "LogisticRegressionCV Accuracy Score:  0.6136363636363636\n",
            "GradientBoostingClassifier Accuracy Score:  0.5454545454545454\n",
            "KMeans Accuracy Score:  0.5227272727272727\n",
            "AgglomerativeClustering Accuracy Score:  0.5\n",
            "SpectralClustering Accuracy Score:  0.4772727272727273\n",
            "KNeighborsClassifier Accuracy Score:  0.7272727272727273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1pk1Kes9TJA",
        "colab_type": "text"
      },
      "source": [
        "## Since We have a 10 fold Strafied Segmented cross validation, and we are using 10 classification algorithms, also the number of parcellations are 14 ..\n",
        "\n",
        "## Therefore we get 14\\*10\\*10 = 1400 accuracy scores. \n",
        "\n",
        "Now we need to only save the accuracy that is the best of cross validation, and its name. \n",
        "\n",
        "We can create a dictionry for the same\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp8WF8635Z1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "baa601db-21e3-4d71-9544-006ae5aa9e46"
      },
      "source": [
        "len(accuracy)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou2JIN-A_Txo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a2bee915-210e-4084-e85b-b0dbb65a6328"
      },
      "source": [
        "accuracy[0:10]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8181818181818182,\n",
              " 0.7954545454545454,\n",
              " 0.7727272727272727,\n",
              " 0.7727272727272727,\n",
              " 0.7727272727272727,\n",
              " 0.75,\n",
              " 0.75,\n",
              " 0.75,\n",
              " 0.75,\n",
              " 0.75]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S2RTEZyAbCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42fe9ac1-9eec-49ae-a093-dc0f0375ac6c"
      },
      "source": [
        "# Important indexes for accuracy that goes above 74%\n",
        "important_indexes = [i for i,x in enumerate(accuracy) if x >= 0.74]\n",
        "print(important_indexes)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeRrrUQbHxCp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "outputId": "3351edc8-9d7a-4373-e4ca-f0cb6d015d5b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.hist(accuracy, 100)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   4.,   0.,   0.,   3.,   0.,   0.,   0.,   0.,   8.,   0.,\n",
              "          0.,   0.,  15.,   0.,   0.,   0.,  22.,   0.,   0.,   0.,  40.,\n",
              "          0.,   0.,  96.,   0.,   0.,   0.,   0., 162.,   0.,   0.,   0.,\n",
              "        145.,   0.,   0.,   0., 144.,   0.,   0.,   0., 136.,   0.,   0.,\n",
              "          0., 132.,   0.,   0.,   0., 114.,   0.,   0.,   0., 114.,   0.,\n",
              "          0.,   0.,  95.,   0.,   0.,  62.,   0.,   0.,   0.,  44.,   0.,\n",
              "          0.,   0.,   0.,  24.,   0.,   0.,   0.,  25.,   0.,   0.,   0.,\n",
              "          9.,   0.,   0.,   0.,   3.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
              "          1.]),\n",
              " array([0.25      , 0.25568182, 0.26136364, 0.26704545, 0.27272727,\n",
              "        0.27840909, 0.28409091, 0.28977273, 0.29545455, 0.30113636,\n",
              "        0.30681818, 0.3125    , 0.31818182, 0.32386364, 0.32954545,\n",
              "        0.33522727, 0.34090909, 0.34659091, 0.35227273, 0.35795455,\n",
              "        0.36363636, 0.36931818, 0.375     , 0.38068182, 0.38636364,\n",
              "        0.39204545, 0.39772727, 0.40340909, 0.40909091, 0.41477273,\n",
              "        0.42045455, 0.42613636, 0.43181818, 0.4375    , 0.44318182,\n",
              "        0.44886364, 0.45454545, 0.46022727, 0.46590909, 0.47159091,\n",
              "        0.47727273, 0.48295455, 0.48863636, 0.49431818, 0.5       ,\n",
              "        0.50568182, 0.51136364, 0.51704545, 0.52272727, 0.52840909,\n",
              "        0.53409091, 0.53977273, 0.54545455, 0.55113636, 0.55681818,\n",
              "        0.5625    , 0.56818182, 0.57386364, 0.57954545, 0.58522727,\n",
              "        0.59090909, 0.59659091, 0.60227273, 0.60795455, 0.61363636,\n",
              "        0.61931818, 0.625     , 0.63068182, 0.63636364, 0.64204545,\n",
              "        0.64772727, 0.65340909, 0.65909091, 0.66477273, 0.67045455,\n",
              "        0.67613636, 0.68181818, 0.6875    , 0.69318182, 0.69886364,\n",
              "        0.70454545, 0.71022727, 0.71590909, 0.72159091, 0.72727273,\n",
              "        0.73295455, 0.73863636, 0.74431818, 0.75      , 0.75568182,\n",
              "        0.76136364, 0.76704545, 0.77272727, 0.77840909, 0.78409091,\n",
              "        0.78977273, 0.79545455, 0.80113636, 0.80681818, 0.8125    ,\n",
              "        0.81818182]),\n",
              " <a list of 100 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAEvCAYAAABGywdiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUOUlEQVR4nO3df+zuZ13f8edbOnQ4J2CPDPvD02lxQ+MiOzIWswXFabWGkkhIG38UxTVOQKdkUtwSli0k1S06zRxJFUZdHEiYk25lcwxxxEXQww/5UUQ6KHA6sEf54TIztHjtj3ODh3LK+fbc3/v7Pad9PJLme3+uz/W5P+/myn3O61zf6/5cs9YKAAAe7D7nsAsAAIDzgWAMAAAJxgAAUAnGAABQCcYAAFAJxgAAUNVFh11A1cUXX7yOHj162GUAAPAA98Y3vvEP1lpHznTuvAjGR48e7fjx44ddBgAAD3Az8777OmcpBQAAJBgDAEAlGAMAQCUYAwBAJRgDAEAlGAMAQCUYAwBAJRgDAEAlGAMAQCUYAwBAtYdgPDMvnpm7Z+bt92p/9sz87sy8Y2Z+4rT2583MHTPzrpn55l0UDQAA++2iPfR5SfWvq1/4ZMPMfH11TfU31lofn5kv3rQ/trq2+srqS6r/PjOPWWt9Yr8LBzjd0RtvO2P7nTddfcCVAHChOuuM8VrrddWH79X8D6qb1lof3/S5e9N+TfWytdbH11rvre6oHr+P9QIAwE6c6xrjx1R/Z2beMDP/Y2a+dtN+SfWB0/qd2LQBAMB5bS9LKe7rukdWT6i+tnr5zPzV+/MGM3NDdUPV5Zdffo5lAADA/jjXGeMT1S+vU36r+rPq4uqu6rLT+l26afsMa62b11rH1lrHjhw5co5lAADA/jjXYPwr1ddXzcxjqodWf1DdWl07M587M1dUV1a/tR+FAgDALp11KcXMvLR6YnXxzJyonl+9uHrx5hFuf1Jdv9Za1Ttm5uXV7dU91TM9kQIAgAvBWYPxWuu6+zj1nffR/wXVC7YpCgAADpqd7wAAIMEYAAAqwRgAACrBGAAAKsEYAAAqwRgAACrBGAAAKsEYAAAqwRgAACrBGAAAKsEYAAAqwRgAACrBGAAAKsEYAAAqwRgAACrBGAAAKsEYAAAqwRgAACrBGAAAqrrosAsAuBAcvfG2+zx3501XH2AlAOyKGWMAAMiMMcB5475mpc1IAxwMM8YAANAegvHMvHhm7p6Zt5/h3HNmZs3MxZvjmZmfmZk7ZuatM/O4XRQNAAD7bS8zxi+prrp348xcVn1T9f7Tmr+lunLz3w3VC7cvEQAAdu+swXit9brqw2c49VPVj1brtLZrql9Yp7y+evjMPHpfKgUAgB06pzXGM3NNddda63fudeqS6gOnHZ/YtAEAwHntfj+VYmYeVv1Yp5ZRnLOZuaFTyy26/PLLt3krAADY2rnMGH9ZdUX1OzNzZ3Vp9aaZ+SvVXdVlp/W9dNP2GdZaN6+1jq21jh05cuQcygAAgP1zv4PxWutta60vXmsdXWsd7dRyicettT5U3Vp99+bpFE+oPrbW+uD+lgwAAPtvL49re2n1m9VXzMyJmXnGZ+n+quo91R3Vz1U/sC9VAgDAjp11jfFa67qznD962utVPXP7sgAA4GDZ+Q4AADqHp1IAcGE6euNtZ2y/86arD7gSgPOTGWMAAEgwBgCASjAGAIBKMAYAgEowBgCASjAGAIDK49oA2EceCQdcyMwYAwBAgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFSCMQAAVIIxAABUgjEAAFR7CMYz8+KZuXtm3n5a27+Ymd+dmbfOzH+cmYefdu55M3PHzLxrZr55V4UDAMB+2suM8Uuqq+7V9urqq9ZaX139XvW8qpl5bHVt9ZWba/7NzDxk36oFAIAdOWswXmu9rvrwvdr+21rrns3h66tLN6+vqV621vr4Wuu91R3V4/exXgAA2In9WGP8vdV/2by+pPrAaedObNoAAOC8tlUwnpl/XN1T/eI5XHvDzByfmeMnT57cpgwAANjaOQfjmXl69W3Vd6y11qb5ruqy07pdumn7DGutm9dax9Zax44cOXKuZQAAwL44p2A8M1dVP1o9ea31x6edurW6dmY+d2auqK6sfmv7MgEAYLcuOluHmXlp9cTq4pk5UT2/U0+h+Nzq1TNT9fq11vevtd4xMy+vbu/UEotnrrU+saviAQBgv5w1GK+1rjtD84s+S/8XVC/YpigAADhodr4DAIAEYwAAqARjAACoBGMAAKgEYwAAqPbwVAoAOF8cvfG2M7bfedPVF8T7A+c3M8YAAJBgDAAAlWAMAACVYAwAAJVgDAAAlWAMAACVYAwAAJVgDAAAlWAMAACVYAwAAJVgDAAAlWAMAACVYAwAAJVgDAAAlWAMAACVYAwAAJVgDAAA1R6C8cy8eGbunpm3n9b2yJl59cy8e/PzEZv2mZmfmZk7ZuatM/O4XRYPAAD7ZS8zxi+prrpX243Va9ZaV1av2RxXfUt15ea/G6oX7k+ZAACwW2cNxmut11UfvlfzNdUtm9e3VE85rf0X1imvrx4+M4/er2IBAGBXznWN8aPWWh/cvP5Q9ajN60uqD5zW78SmDQAAzmtbf/lurbWqdX+vm5kbZub4zBw/efLktmUAAMBWzjUY//4nl0hsft69ab+ruuy0fpdu2j7DWuvmtdaxtdaxI0eOnGMZAACwP841GN9aXb95fX31ytPav3vzdIonVB87bckFAACcty46W4eZeWn1xOrimTlRPb+6qXr5zDyjel/1tE33V1XfWt1R/XH1PTuoGQAA9t1Zg/Fa67r7OPWkM/Rd1TO3LQoAAA6ane8AAKA9zBgD3B9Hb7ztjO133nT1AVcCAPePGWMAAMiMMQAcKL9VgfOXGWMAAEgwBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgGrLYDwzPzwz75iZt8/MS2fm82bmipl5w8zcMTO/NDMP3a9iAQBgV845GM/MJdUPVsfWWl9VPaS6tvrx6qfWWl9efaR6xn4UCgAAu7TtUoqLqr84MxdVD6s+WH1D9YrN+Vuqp2x5DwAA2LlzDsZrrbuqf1m9v1OB+GPVG6uPrrXu2XQ7UV2ybZEAALBr2yyleER1TXVF9SXV51dX3Y/rb5iZ4zNz/OTJk+daBgAA7IttllJ8Y/XetdbJtdafVr9cfV318M3SiqpLq7vOdPFa6+a11rG11rEjR45sUQYAAGxvm2D8/uoJM/OwmZnqSdXt1Wurp276XF+9crsSAQBg97ZZY/yGTn3J7k3V2zbvdXP13OpHZuaO6ouqF+1DnQAAsFMXnb3LfVtrPb96/r2a31M9fpv3BQCAg2bnOwAASDAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBKMAYAgEowBgCASjAGAIBqy2A8Mw+fmVfMzO/OzDtn5m/PzCNn5tUz8+7Nz0fsV7EAALArF215/U9X/3Wt9dSZeWj1sOrHqtestW6amRurG6vnbnkfAOA0R2+87Yztd9509QFXAg8c5zxjPDNfWP3d6kVVa60/WWt9tLqmumXT7ZbqKdsWCQAAu7bNUoorqpPVv52ZN8/Mz8/M51ePWmt9cNPnQ9Wjti0SAAB2bZtgfFH1uOqFa62vqf5vp5ZNfMpaa1XrTBfPzA0zc3xmjp88eXKLMgAAYHvbBOMT1Ym11hs2x6/oVFD+/Zl5dNXm591nunitdfNa69ha69iRI0e2KAMAALZ3zsF4rfWh6gMz8xWbpidVt1e3Vtdv2q6vXrlVhQAAcAC2fSrFs6tf3DyR4j3V93QqbL98Zp5Rva962pb3AACAndsqGK+13lIdO8OpJ23zvgAAcNDsfAcAAAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQCcYAAFAJxgAAUAnGAABQ1UWHXQAAcP45euNtZ2y/86arD7gSODhmjAEAIMEYAACqfQjGM/OQmXnzzPznzfEVM/OGmbljZn5pZh66fZkAALBb+zFj/EPVO087/vHqp9ZaX159pHrGPtwDAAB2aqtgPDOXVldXP785nuobqldsutxSPWWbewAAwEHYdsb4X1U/Wv3Z5viLqo+ute7ZHJ+oLtnyHgAAsHPn/Li2mfm26u611htn5onncP0N1Q1Vl19++bmWAeyD+3osU3k0EwAPHtvMGH9d9eSZubN6WaeWUPx09fCZ+WTgvrS660wXr7VuXmsdW2sdO3LkyBZlAADA9s45GK+1nrfWunStdbS6tvq1tdZ3VK+tnrrpdn31yq2rBACAHdvFc4yfW/3IzNzRqTXHL9rBPQAAYF/ty5bQa61fr3598/o91eP3430BAOCg2PkOAAASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKCqiw67AACAg3T0xtvO2H7nTVcfcCWcbwRjAOC8IrhyWCylAACABGMAAKi2CMYzc9nMvHZmbp+Zd8zMD23aHzkzr56Zd29+PmL/ygUAgN3YZo3xPdVz1lpvmpkvqN44M6+unl69Zq1108zcWN1YPXf7UuHBy3o7ANi9c54xXmt9cK31ps3r/1O9s7qkuqa6ZdPtluop2xYJAAC7ti9rjGfmaPU11RuqR621Prg59aHqUftxDwAA2KWtg/HM/KXqP1T/cK31R6efW2utat3HdTfMzPGZOX7y5MltywAAgK1sFYxn5i90KhT/4lrrlzfNvz8zj96cf3R195muXWvdvNY6ttY6duTIkW3KAACArW3zVIqpXlS9c631k6edurW6fvP6+uqV514eAAAcjG2eSvF11XdVb5uZt2zafqy6qXr5zDyjel/1tO1KBACA3TvnYLzW+o1q7uP0k871fQEA4DDY+Q4AABKMAQCgEowBAKDa7st3wIYtmwHgwmfGGAAAEowBAKASjAEAoBKMAQCgEowBAKASjAEAoBKMAQCgEowBAKCywQcAwL6y6dOFy4wxAABkxpgHAf9yBwD2wowxAAAkGAMAQCUYAwBAJRgDAEAlGAMAQOWpFOyBpzoAAA8GZowBACAzxhwgM88AsD/8nbobO5sxnpmrZuZdM3PHzNy4q/sAAMB+2EkwnpmHVD9bfUv12Oq6mXnsLu4FAAD7YVdLKR5f3bHWek/VzLysuqa6fUf3O2d+FQEA8On2Kx9daDlrV0spLqk+cNrxiU0bAACcl2attf9vOvPU6qq11vdtjr+r+ltrrWed1ueG6obN4VdU79r3Qh68Lq7+4LCLYE+M1YXDWF1YjNeFw1hdOB4oY/Wla60jZzqxq6UUd1WXnXZ86abtU9ZaN1c37+j+D2ozc3ytdeyw6+DsjNWFw1hdWIzXhcNYXTgeDGO1q6UUv11dOTNXzMxDq2urW3d0LwAA2NpOZozXWvfMzLOqX60eUr14rfWOXdwLAAD2w842+Fhrvap61a7en8/KEpULh7G6cBirC4vxunAYqwvHA36sdvLlOwAAuNDsbOc7AAC4kAjGF7Czbbs9M98/M2+bmbfMzG/YffDw7HWL9Jn59plZM/OA/tbv+WwPn6unz8zJzefqLTPzfYdRJ3v7XM3M02bm9pl5x8z8+4OukVP28Ln6qdM+U783Mx89jDo5ZQ/jdfnMvHZm3jwzb52Zbz2MOnfBUooL1Gbb7d+r/l6nNlD57eq6tdbtp/X5y2utP9q8fnL1A2utqw6j3gezvYzVpt8XVLdVD62etdY6ftC1Ptjt8XP19OrY6c9l5+DtcayurF5efcNa6yMz88VrrbsPpeAHsb3+GXha/2dXX7PW+t6Dq5JP2uNn6+bqzWutF24m3V611jp6GPXuNzPGF65Pbbu91vqT6pPbbn/KJ0PxxudX/hV0OM46Vhv/vPrx6v8dZHF8mr2OFYdvL2P196ufXWt9pEooPjT393N1XfXSA6mMM9nLeK3qL29ef2H1vw+wvp0SjC9ce9p2e2aeOTP/q/qJ6gcPqDY+3VnHamYeV1221jrzpvIclL1uZ//tm18fvmJmLjvDeXZvL2P1mOoxM/M/Z+b1M+M3Zodjr5+rZuZLqyuqXzuAujizvYzXP62+c2ZOdOoJZM8+mNJ2TzB+gFtr/exa68uq51b/5LDr4TPNzOdUP1k957BrYU/+U3V0rfXV1aurWw65Hu7bRdWV1RM7NQv5czPz8EOtiLO5tnrFWusTh10In9V11UvWWpdW31r9u83fZRe8B8T/xIPUWbfdvpeXVU/ZaUXcl7ON1RdUX1X9+szcWT2hutUX8A7FXraz/8O11sc3hz9f/c0Dqo1Pt5c/A09Ut661/nSt9d5OrZu88oDq48/dn7+vrs0yisO2l/F6RqfW77fW+s3q86qLD6S6HROML1xn3XZ788WTT7q6evcB1sef+6xjtdb62Frr4rXW0c2XF15fPdmX7w7FXj5Xjz7t8MnVOw+wPv7cWceq+pVOzRY3Mxd3amnFew6ySKq9jVUz89eqR1S/ecD18en2Ml7vr55UNTN/vVPB+OSBVrkjO9v5jt26r223Z+afVcfXWrdWz5qZb6z+tPpIdf3hVfzgtcex4jywx7H6wc1TXu6pPlw9/dAKfhDb41j9avVNM3N79YnqH621/vDwqn5wuh9/Bl5bvWx5XNah2uN4PadTS5N+uFNfxHv6A2XcPK4NAACylAIAACrBGAAAKsEYAAAqwRgAACrBGAAAKsEYAAAqwRgAACrBGAAAqvr/gkQnbNVbT38AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkqJg_e4BeNg",
        "colab_type": "text"
      },
      "source": [
        "# Performing same to get best accuracy models and save them\n",
        "\n",
        "this can be done using dictionaries\n",
        "\n",
        "\n",
        "# This part I'm working out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xYtPyk7CQ3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9702b8b2-4dc4-443a-c2df-683e78b18480"
      },
      "source": [
        "X_train, X_test = X[:][train_index], X[:][test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(43, 70) (43,)\n",
            "(44, 70) (44,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPXzyfzCMFjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = {aal: {model: best_accuracy, model2: best accuracy}, 2: {model: best_accuracy}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50eJ3s9MBdGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_names = list()\n",
        "best_score = list()\n",
        "\n",
        "for i, nm in enumerate(df):\n",
        "  best_score.append(accuracy_best)\n",
        "  accuracy_best = list()\n",
        "\n",
        "  ## Since there are only 14 types of parcellations in ReHo data, rest of the \n",
        "  ## variabes are not useful for classification\n",
        "\n",
        "  if i > 13:\n",
        "    pass\n",
        "  else:\n",
        "    print(i, nm)\n",
        "    X = df.get(nm)\n",
        "    y = np.array(df.get('diag_Code'))\n",
        "    print(X.shape, y.shape)\n",
        "    X = np.array(X)\n",
        "\n",
        "    # Strafied Shuffle Split\n",
        "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.5, random_state=0)\n",
        "\n",
        "    for train_index, test_index in sss.split(X, y):\n",
        "      accuracy_best.append(accuracy.max)\n",
        "      accuracy = [[]]\n",
        "\n",
        "\n",
        "      print(\"TRAIN:\", train_index[1:5], \"TEST:\", test_index[1:5])\n",
        "      X_train, X_test = X[:][train_index], X[:][test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "      print(X_train.shape, y_train.shape)\n",
        "      print(X_test.shape, y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "      lr = LinearRegression()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = LogisticRegression()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = LogisticRegressionCV()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = DecisionTreeClassifier()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = RandomForestClassifier()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = GradientBoostingClassifier()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = KMeans()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = AgglomerativeClustering()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.fit_predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "      lr = SpectralClustering()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.fit_predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))\n",
        "\n",
        "\n",
        "      lr = KNeighborsClassifier()\n",
        "      clf = lr.fit(X_train, y_train)\n",
        "      y_hat = clf.predict(X_test)\n",
        "      y_hat = y_hat > 0\n",
        "      model_names.append(lr.__class__.__name__)\n",
        "      accuracy.append(accuracy_score(y_test, y_hat))\n",
        "      print(lr.__class__.__name__, 'Accuracy Score: ',accuracy_score(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJNiiaEO1yXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "afda3677-d767-4de1-ef76-29868fbce6a3"
      },
      "source": [
        "X[:][1]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    -1.379881\n",
              "1    -0.774012\n",
              "2     0.659692\n",
              "3     0.391177\n",
              "4    -1.272483\n",
              "        ...   \n",
              "82   -0.658905\n",
              "83   -0.596178\n",
              "84    1.649737\n",
              "85    2.832984\n",
              "86   -0.616909\n",
              "Name: 1, Length: 87, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVOL-mqH101u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33469a35-2182-4a16-a11c-178138c69ebb"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEJcb1Noy8SP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "15df6472-cc72-4981-da79-913be797e4b6"
      },
      "source": [
        " X_train[1], y_train[1]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    -1.379881\n",
              " 1    -0.774012\n",
              " 2     0.659692\n",
              " 3     0.391177\n",
              " 4    -1.272483\n",
              "         ...   \n",
              " 82   -0.658905\n",
              " 83   -0.596178\n",
              " 84    1.649737\n",
              " 85    2.832984\n",
              " 86   -0.616909\n",
              " Name: 1, Length: 87, dtype: float64, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISjKxaiMbzDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compare ensemble to each baseline classifier\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
        "\treturn X, y\n",
        " \n",
        "# get a stacking ensemble of models\n",
        "def get_stacking():\n",
        "\t# define the base models\n",
        "\tlevel0 = list()\n",
        "\tlevel0.append(('lr', LogisticRegression()))\n",
        "\tlevel0.append(('knn', KNeighborsClassifier()))\n",
        "\tlevel0.append(('cart', DecisionTreeClassifier()))\n",
        "\tlevel0.append(('svm', SVC()))\n",
        "\tlevel0.append(('bayes', GaussianNB()))\n",
        "\t# define meta learner model\n",
        "\tlevel1 = LogisticRegression()\n",
        "\t# define the stacking ensemble\n",
        "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
        "\treturn model\n",
        " \n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['lr'] = LogisticRegression()\n",
        "\tmodels['knn'] = KNeighborsClassifier()\n",
        "\tmodels['cart'] = DecisionTreeClassifier()\n",
        "\tmodels['svm'] = SVC()\n",
        "\tmodels['bayes'] = GaussianNB()\n",
        "\tmodels['stacking'] = get_stacking()\n",
        "\treturn models\n",
        " \n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        " \n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E1Kx7-0VD_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n995nauUVDtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PdmZRAOVDsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDMS0BilVDgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0A8bhh3TOXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpGmTGvINV3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3hxuqcAMWiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kJx11GNMWgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGv3OVnFMWL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfGv9jXxMWJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuyBMH77MWHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA9u9zjBMV8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rkJ7K68MV6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8hGC9ZDMV3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2alBGLbMVm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVwOPHuNMVj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nSPKRoIMVVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall hunga-bunga\n",
        "!pip install hunga-bunga"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bXrpo-VLb0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "9a8746b0-a995-47ad-ac9c-75493e7ceb5c"
      },
      "source": [
        "!pip uninstall hunga-bunga\n",
        "!pip install hunga-bunga"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling hunga-bunga-0.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/hunga_bunga-0.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/hunga_bunga/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled hunga-bunga-0.1\n",
            "Processing /root/.cache/pip/wheels/e5/d7/7c/154325b2c53eba43f2b9bcaadf4b9c9de157e1e9316d398fed/hunga_bunga-0.1-cp36-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hunga-bunga) (1.18.5)\n",
            "Installing collected packages: hunga-bunga\n",
            "Successfully installed hunga-bunga-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1z5_xWIX5wn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d02e67dd-b55e-4331-8733-c7f7821c152e"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0   206    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   206  100   206    0     0    513      0 --:--:-- --:--:-- --:--:--   512\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (49.1.0)\n",
            "Requirement already satisfied: pytest>=4.6 in /usr/local/lib/python3.6/dist-packages (5.4.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6) (1.9.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6) (0.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6) (20.4)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6) (8.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6) (1.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->pytest>=4.6) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->pytest>=4.6) (1.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.6) (3.1.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.14.1) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn<0.23,>=0.22.0 in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.23,>=0.22.0) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.23,>=0.22.0) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.23,>=0.22.0) (1.4.1)\n",
            "Requirement already satisfied: lockfile in /usr/local/lib/python3.6/dist-packages (0.12.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: pandas<1.0 in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas<1.0) (1.12.0)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (0.4.13)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (2.4.7)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (0.29.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (1.18.5)\n",
            "Requirement already satisfied: pynisher>=0.4.2 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2) (5.4.8)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2) (49.1.0)\n",
            "Collecting pyrfr<0.9,>=0.7\n",
            "  Using cached https://files.pythonhosted.org/packages/ed/0f/4d7e42a9dfef3a1898e03cffa8f1cfcd1f96507d718808b2db584c6f8401/pyrfr-0.8.0.tar.gz\n",
            "Building wheels for collected packages: pyrfr\n",
            "  Building wheel for pyrfr (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyrfr\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pyrfr\n",
            "Failed to build pyrfr\n",
            "Installing collected packages: pyrfr\n",
            "    Running setup.py install for pyrfr ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-xxhkbk7j/pyrfr/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-xxhkbk7j/pyrfr/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-zomjv0q5/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
            "Processing /root/.cache/pip/wheels/37/36/99/2dbeb54a336b7c78f2bb3c1b418086795b7fbe2c4be8da2d9a/smac-0.12.2-cp36-none-any.whl\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.9 in /usr/local/lib/python3.6/dist-packages (from smac>=0.12) (0.4.13)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from smac>=0.12) (5.4.8)\n",
            "Collecting sobol-seq\n",
            "  Using cached https://files.pythonhosted.org/packages/e4/df/6c4ad25c0b48545a537b631030f7de7e4abb939e6d2964ac2169d4379c85/sobol_seq-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from smac>=0.12) (0.16.0)\n",
            "Collecting pyrfr>=0.8.0\n",
            "  Using cached https://files.pythonhosted.org/packages/ed/0f/4d7e42a9dfef3a1898e03cffa8f1cfcd1f96507d718808b2db584c6f8401/pyrfr-0.8.0.tar.gz\n",
            "Processing /root/.cache/pip/wheels/a9/b0/b5/8c7e6810aee14bc4ed4a542ce56e744126263bf4f4825a9094/lazy_import-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pynisher>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from smac>=0.12) (0.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from smac>=0.12) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from smac>=0.12) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from smac>=0.12) (1.4.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.9->smac>=0.12) (0.29.21)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.9->smac>=0.12) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from lazy-import->smac>=0.12) (1.12.0)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.1->smac>=0.12) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.1->smac>=0.12) (49.1.0)\n",
            "Building wheels for collected packages: pyrfr\n",
            "  Building wheel for pyrfr (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyrfr\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pyrfr\n",
            "Failed to build pyrfr\n",
            "Installing collected packages: sobol-seq, pyrfr, lazy-import, smac\n",
            "    Running setup.py install for pyrfr ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-znb5wep5/pyrfr/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-znb5wep5/pyrfr/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-6tltmty2/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLFFSe4tJXxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0054a19b-a1f2-4d50-a08f-b8f605543bc3"
      },
      "source": [
        "!pip install hunga-bunga\n",
        "!pip install auto-sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hunga-bunga in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hunga-bunga) (1.18.5)\n",
            "Collecting auto-sklearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/dd/590237d488627a7856fc51d67d2bd801601deecfbb500d6daaf66f641462/auto-sklearn-0.8.0.tar.gz (4.6MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (49.1.0)\n",
            "Collecting pytest>=4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f3/0a83558da436a081344aa6c8b85ea5b5f05071214106036ce341b7769b0b/pytest-5.4.3-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 24.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.29.21)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn<0.23,>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.22.2.post1)\n",
            "Collecting lockfile\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/22/9460e311f340cb62d26a38c419b1381b8593b0bb6b5d1f056938b086d362/lockfile-0.12.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
            "Collecting liac-arff\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/35/fbc9217cfa91d98888b43e1a19c03a50d716108c58494c558c65e308f372/liac-arff-2.4.0.tar.gz\n",
            "Collecting pandas<1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 26.4MB/s \n",
            "\u001b[?25hCollecting ConfigSpace<0.5,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/66/c9de12ba36e7ea396684101fdba05fc22fec8c312693f0398aef96b06298/ConfigSpace-0.4.13.tar.gz (964kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 48.3MB/s \n",
            "\u001b[?25hCollecting pynisher>=0.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/21/c86c64c305da6d43fb89780d33cbc839c07736b71955a8bdb642a02b7538/pynisher-0.5.0.tar.gz\n",
            "Collecting pyrfr<0.9,>=0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/0f/4d7e42a9dfef3a1898e03cffa8f1cfcd1f96507d718808b2db584c6f8401/pyrfr-0.8.0.tar.gz (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 46.8MB/s \n",
            "\u001b[?25hCollecting smac>=0.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/31/eb9806705d01c3211b729dd58117f6ab5337558e7f6dbff54bd93a42c3c3/smac-0.12.2.tar.gz (214kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6->auto-sklearn) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6->auto-sklearn) (8.4.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6->auto-sklearn) (1.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6->auto-sklearn) (20.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.6->auto-sklearn) (0.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0->auto-sklearn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.4.7)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2->auto-sklearn) (0.15.2)\n",
            "Collecting sobol_seq\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/df/6c4ad25c0b48545a537b631030f7de7e4abb939e6d2964ac2169d4379c85/sobol_seq-0.2.0-py3-none-any.whl\n",
            "Collecting lazy_import\n",
            "  Downloading https://files.pythonhosted.org/packages/44/2e/5378f9b9cbc893826c2ecb022646c97ece9efbaad351adf89425fff33990/lazy_import-0.2.2.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->pytest>=4.6->auto-sklearn) (1.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.6->auto-sklearn) (3.1.0)\n",
            "Building wheels for collected packages: auto-sklearn, liac-arff, ConfigSpace, pynisher, pyrfr, smac, lazy-import\n",
            "  Building wheel for auto-sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.8.0-cp36-none-any.whl size=4842901 sha256=04c9d1ec16938c44ec35e6b45ca189175816ac4a4d1050f71fafd812895f703e\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/53/3a/288c5bab272d38177e5188e59525363bfeeb8fc6f1784ddb2e\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.4.0-cp36-none-any.whl size=13335 sha256=be84e5bbdae94d3eaaad9f933f99501528c7ed8a8b66924611730a9c1fa8416a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/6a/e7/529dc54d76ecede4346164a09ae3168df358945612710f5203\n",
            "  Building wheel for ConfigSpace (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.13-cp36-cp36m-linux_x86_64.whl size=2913479 sha256=1f9202a3ef9b209f02de95996fab2f1a70190439da720fb1fc45e405ff4daac6\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/13/67/89f852e4a5cf173e6c7da5e9d449b8e98483bc8168cf7b6e6d\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynisher: filename=pynisher-0.5.0-cp36-none-any.whl size=4360 sha256=0698d7f06798528c497218a3c6b5591b7148a3c4a763909a3ddac61da6c7bbda\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/2a/c4/ec3abc8a2f786ef9786ea8fe6ff629a4e54812a3f98cc41b47\n",
            "  Building wheel for pyrfr (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyrfr\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pyrfr\n",
            "  Building wheel for smac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smac: filename=smac-0.12.2-cp36-none-any.whl size=216080 sha256=70c1b742b5bb3490db47ae59e3bcfaf9564349ee1489d2dbd458f3b7a1d014ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/36/99/2dbeb54a336b7c78f2bb3c1b418086795b7fbe2c4be8da2d9a\n",
            "  Building wheel for lazy-import (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lazy-import: filename=lazy_import-0.2.2-py2.py3-none-any.whl size=16485 sha256=6b3b7271dd68c6bcf7c8bf82f02bff0e18e3c206f005e11a256995bdc5301a67\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/b0/b5/8c7e6810aee14bc4ed4a542ce56e744126263bf4f4825a9094\n",
            "Successfully built auto-sklearn liac-arff ConfigSpace pynisher smac lazy-import\n",
            "Failed to build pyrfr\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pluggy, pytest, lockfile, liac-arff, pandas, ConfigSpace, pynisher, pyrfr, sobol-seq, lazy-import, smac, auto-sklearn\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas 1.0.5\n",
            "    Uninstalling pandas-1.0.5:\n",
            "      Successfully uninstalled pandas-1.0.5\n",
            "    Running setup.py install for pyrfr ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_73rzcp4/pyrfr/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_73rzcp4/pyrfr/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-uhpp2e35/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUGEMopEKYEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "8bdf348b-45ef-44c5-d01b-eeb831495245"
      },
      "source": [
        "import autosklearn.classification\n",
        "cls = autosklearn.classification.AutoSklearnClassifier()\n",
        "cls.fit(aal, y)\n",
        "predictions = cls.predict(aal)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ee206567d851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautosklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoSklearnClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Wz7g53JXhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "58a9a8e6-713e-4530-b418-83ce5c7c8812"
      },
      "source": [
        "from hunga_bunga import HungaBungaClassifier, HungaBungaRegressor\n",
        "\n",
        "clf = HungaBungaClassifier()\n",
        "clf.fit(X, y)\n",
        "clf.predict(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d0e50a0373f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhunga_bunga\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHungaBungaClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHungaBungaRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHungaBungaClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hunga_bunga/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHungaBungaRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHungaBungaClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'regression'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI2es18jI-xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "frames = []\n",
        "mid = []\n",
        "b = []\n",
        "l = []\n",
        "for i,x in enumerate(df):\n",
        "  l = df.get(x)\n",
        "  try:\n",
        "    a = pd.DataFrame(l, columns=['{}-{}'.format(str(x),i) for i in range(l.shape[1])], index = ['{}'.format(i) for i in range(l.shape[0])] ).transpose()\n",
        "  except:\n",
        "    b = pd.DataFrame({x : l}).transpose()\n",
        "  frames.append(a) \n",
        "  mid.append(b)\n",
        "result = pd.concat(frames).transpose()\n",
        "mid = pd.concat(mid[-5:]).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcHvhctvlQtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "77df91df-06e1-4ddb-d164-a2b5a6dc3c12"
      },
      "source": [
        "a = []\n",
        "frames = []\n",
        "mid = []\n",
        "b = []\n",
        "l = []\n",
        "for i,x in enumerate(df):\n",
        "  l = df.get(x)\n",
        "  try:\n",
        "    a = pd.DataFrame(l, columns=['{}-{}'.format(str(x),i) for i in range(l.shape[1])], index = ['{}'.format(i) for i in range(l.shape[0])] ).transpose()\n",
        "  except:\n",
        "    b = pd.DataFrame({x : l}).transpose()\n",
        "  frames.append(a) \n",
        "  mid.append(b)\n",
        "result = pd.concat(frames).transpose()\n",
        "mid = pd.concat(mid[-5:]).transpose()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aal-0</th>\n",
              "      <th>aal-1</th>\n",
              "      <th>aal-2</th>\n",
              "      <th>aal-3</th>\n",
              "      <th>aal-4</th>\n",
              "      <th>aal-5</th>\n",
              "      <th>aal-6</th>\n",
              "      <th>aal-7</th>\n",
              "      <th>aal-8</th>\n",
              "      <th>aal-9</th>\n",
              "      <th>aal-10</th>\n",
              "      <th>aal-11</th>\n",
              "      <th>aal-12</th>\n",
              "      <th>aal-13</th>\n",
              "      <th>aal-14</th>\n",
              "      <th>aal-15</th>\n",
              "      <th>aal-16</th>\n",
              "      <th>aal-17</th>\n",
              "      <th>aal-18</th>\n",
              "      <th>aal-19</th>\n",
              "      <th>aal-20</th>\n",
              "      <th>aal-21</th>\n",
              "      <th>aal-22</th>\n",
              "      <th>aal-23</th>\n",
              "      <th>aal-24</th>\n",
              "      <th>aal-25</th>\n",
              "      <th>aal-26</th>\n",
              "      <th>aal-27</th>\n",
              "      <th>aal-28</th>\n",
              "      <th>aal-29</th>\n",
              "      <th>aal-30</th>\n",
              "      <th>aal-31</th>\n",
              "      <th>aal-32</th>\n",
              "      <th>aal-33</th>\n",
              "      <th>aal-34</th>\n",
              "      <th>aal-35</th>\n",
              "      <th>aal-36</th>\n",
              "      <th>aal-37</th>\n",
              "      <th>aal-38</th>\n",
              "      <th>aal-39</th>\n",
              "      <th>...</th>\n",
              "      <th>smith70-30</th>\n",
              "      <th>smith70-31</th>\n",
              "      <th>smith70-32</th>\n",
              "      <th>smith70-33</th>\n",
              "      <th>smith70-34</th>\n",
              "      <th>smith70-35</th>\n",
              "      <th>smith70-36</th>\n",
              "      <th>smith70-37</th>\n",
              "      <th>smith70-38</th>\n",
              "      <th>smith70-39</th>\n",
              "      <th>smith70-40</th>\n",
              "      <th>smith70-41</th>\n",
              "      <th>smith70-42</th>\n",
              "      <th>smith70-43</th>\n",
              "      <th>smith70-44</th>\n",
              "      <th>smith70-45</th>\n",
              "      <th>smith70-46</th>\n",
              "      <th>smith70-47</th>\n",
              "      <th>smith70-48</th>\n",
              "      <th>smith70-49</th>\n",
              "      <th>smith70-50</th>\n",
              "      <th>smith70-51</th>\n",
              "      <th>smith70-52</th>\n",
              "      <th>smith70-53</th>\n",
              "      <th>smith70-54</th>\n",
              "      <th>smith70-55</th>\n",
              "      <th>smith70-56</th>\n",
              "      <th>smith70-57</th>\n",
              "      <th>smith70-58</th>\n",
              "      <th>smith70-59</th>\n",
              "      <th>smith70-60</th>\n",
              "      <th>smith70-61</th>\n",
              "      <th>smith70-62</th>\n",
              "      <th>smith70-63</th>\n",
              "      <th>smith70-64</th>\n",
              "      <th>smith70-65</th>\n",
              "      <th>smith70-66</th>\n",
              "      <th>smith70-67</th>\n",
              "      <th>smith70-68</th>\n",
              "      <th>smith70-69</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.903504</td>\n",
              "      <td>-1.379881</td>\n",
              "      <td>1.815419</td>\n",
              "      <td>0.692680</td>\n",
              "      <td>3.219530</td>\n",
              "      <td>1.762107</td>\n",
              "      <td>1.002799</td>\n",
              "      <td>-1.537369</td>\n",
              "      <td>2.796549</td>\n",
              "      <td>0.593156</td>\n",
              "      <td>-0.255145</td>\n",
              "      <td>-2.527846</td>\n",
              "      <td>1.216521</td>\n",
              "      <td>-1.954173</td>\n",
              "      <td>3.158594</td>\n",
              "      <td>0.682909</td>\n",
              "      <td>-1.125890</td>\n",
              "      <td>-3.486496</td>\n",
              "      <td>-0.572924</td>\n",
              "      <td>-0.489566</td>\n",
              "      <td>2.271910</td>\n",
              "      <td>1.970850</td>\n",
              "      <td>0.654350</td>\n",
              "      <td>1.198993</td>\n",
              "      <td>1.852338</td>\n",
              "      <td>2.058460</td>\n",
              "      <td>2.447902</td>\n",
              "      <td>2.860240</td>\n",
              "      <td>0.170609</td>\n",
              "      <td>-3.189064</td>\n",
              "      <td>-0.076566</td>\n",
              "      <td>0.101435</td>\n",
              "      <td>-3.019396</td>\n",
              "      <td>-3.840099</td>\n",
              "      <td>-2.266207</td>\n",
              "      <td>-2.497234</td>\n",
              "      <td>1.306596</td>\n",
              "      <td>-1.818076</td>\n",
              "      <td>0.649514</td>\n",
              "      <td>-0.711509</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.427312</td>\n",
              "      <td>-0.554650</td>\n",
              "      <td>1.343916</td>\n",
              "      <td>-0.837381</td>\n",
              "      <td>-0.585421</td>\n",
              "      <td>0.095032</td>\n",
              "      <td>-2.657656</td>\n",
              "      <td>1.210853</td>\n",
              "      <td>-3.428913</td>\n",
              "      <td>1.165785</td>\n",
              "      <td>0.996149</td>\n",
              "      <td>0.484851</td>\n",
              "      <td>-0.600837</td>\n",
              "      <td>-0.416758</td>\n",
              "      <td>-1.862204</td>\n",
              "      <td>0.822299</td>\n",
              "      <td>-0.543847</td>\n",
              "      <td>0.726232</td>\n",
              "      <td>0.366906</td>\n",
              "      <td>0.500763</td>\n",
              "      <td>-0.918343</td>\n",
              "      <td>-0.522601</td>\n",
              "      <td>0.985143</td>\n",
              "      <td>0.309880</td>\n",
              "      <td>0.199832</td>\n",
              "      <td>-1.995937</td>\n",
              "      <td>0.119034</td>\n",
              "      <td>1.910153</td>\n",
              "      <td>-0.794655</td>\n",
              "      <td>2.377925</td>\n",
              "      <td>0.742295</td>\n",
              "      <td>-2.176832</td>\n",
              "      <td>0.037749</td>\n",
              "      <td>1.221252</td>\n",
              "      <td>-0.051657</td>\n",
              "      <td>1.360693</td>\n",
              "      <td>-0.410199</td>\n",
              "      <td>1.106303</td>\n",
              "      <td>0.319606</td>\n",
              "      <td>-0.563350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.005250</td>\n",
              "      <td>-0.774012</td>\n",
              "      <td>0.297203</td>\n",
              "      <td>0.567038</td>\n",
              "      <td>-1.553331</td>\n",
              "      <td>2.111693</td>\n",
              "      <td>0.099713</td>\n",
              "      <td>-0.396241</td>\n",
              "      <td>-0.456515</td>\n",
              "      <td>1.884615</td>\n",
              "      <td>0.053794</td>\n",
              "      <td>0.694751</td>\n",
              "      <td>-0.233670</td>\n",
              "      <td>0.277691</td>\n",
              "      <td>0.492492</td>\n",
              "      <td>0.197456</td>\n",
              "      <td>0.372023</td>\n",
              "      <td>0.567832</td>\n",
              "      <td>0.492808</td>\n",
              "      <td>1.240741</td>\n",
              "      <td>-0.292228</td>\n",
              "      <td>1.023248</td>\n",
              "      <td>1.865757</td>\n",
              "      <td>1.119135</td>\n",
              "      <td>-0.889321</td>\n",
              "      <td>-1.299834</td>\n",
              "      <td>-1.373710</td>\n",
              "      <td>-0.191514</td>\n",
              "      <td>-1.253117</td>\n",
              "      <td>0.937337</td>\n",
              "      <td>1.580214</td>\n",
              "      <td>1.032260</td>\n",
              "      <td>3.396746</td>\n",
              "      <td>3.421665</td>\n",
              "      <td>2.736670</td>\n",
              "      <td>1.789535</td>\n",
              "      <td>1.085319</td>\n",
              "      <td>0.268563</td>\n",
              "      <td>0.857363</td>\n",
              "      <td>-0.616249</td>\n",
              "      <td>...</td>\n",
              "      <td>1.667381</td>\n",
              "      <td>0.039795</td>\n",
              "      <td>-0.266618</td>\n",
              "      <td>-0.467590</td>\n",
              "      <td>1.485558</td>\n",
              "      <td>2.253628</td>\n",
              "      <td>-1.316971</td>\n",
              "      <td>-1.374695</td>\n",
              "      <td>1.044823</td>\n",
              "      <td>0.780941</td>\n",
              "      <td>-0.056501</td>\n",
              "      <td>-0.803732</td>\n",
              "      <td>0.009191</td>\n",
              "      <td>-0.119740</td>\n",
              "      <td>-0.108351</td>\n",
              "      <td>-0.571004</td>\n",
              "      <td>-0.528105</td>\n",
              "      <td>0.232451</td>\n",
              "      <td>0.187104</td>\n",
              "      <td>0.771036</td>\n",
              "      <td>-0.493726</td>\n",
              "      <td>-1.115443</td>\n",
              "      <td>-1.467692</td>\n",
              "      <td>-0.508843</td>\n",
              "      <td>0.227144</td>\n",
              "      <td>-1.739882</td>\n",
              "      <td>-0.466618</td>\n",
              "      <td>0.436533</td>\n",
              "      <td>-1.091325</td>\n",
              "      <td>-0.478555</td>\n",
              "      <td>0.963358</td>\n",
              "      <td>-0.651643</td>\n",
              "      <td>0.344092</td>\n",
              "      <td>-0.720894</td>\n",
              "      <td>-0.103521</td>\n",
              "      <td>-0.989457</td>\n",
              "      <td>-0.054083</td>\n",
              "      <td>0.692951</td>\n",
              "      <td>0.758725</td>\n",
              "      <td>2.094716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.570857</td>\n",
              "      <td>0.659692</td>\n",
              "      <td>-0.606319</td>\n",
              "      <td>-0.922331</td>\n",
              "      <td>-0.181489</td>\n",
              "      <td>-0.669323</td>\n",
              "      <td>0.116768</td>\n",
              "      <td>-0.543971</td>\n",
              "      <td>-0.314008</td>\n",
              "      <td>-0.697251</td>\n",
              "      <td>-0.075673</td>\n",
              "      <td>0.683390</td>\n",
              "      <td>-0.147586</td>\n",
              "      <td>0.520724</td>\n",
              "      <td>-0.031966</td>\n",
              "      <td>-0.642244</td>\n",
              "      <td>0.154361</td>\n",
              "      <td>0.324440</td>\n",
              "      <td>-0.015973</td>\n",
              "      <td>-0.926121</td>\n",
              "      <td>-0.599857</td>\n",
              "      <td>-0.093675</td>\n",
              "      <td>0.623150</td>\n",
              "      <td>-0.614754</td>\n",
              "      <td>0.073104</td>\n",
              "      <td>-0.467231</td>\n",
              "      <td>-0.773465</td>\n",
              "      <td>-0.761976</td>\n",
              "      <td>-0.262380</td>\n",
              "      <td>0.909204</td>\n",
              "      <td>0.017039</td>\n",
              "      <td>1.220186</td>\n",
              "      <td>1.799216</td>\n",
              "      <td>1.397674</td>\n",
              "      <td>2.207531</td>\n",
              "      <td>2.049861</td>\n",
              "      <td>0.404792</td>\n",
              "      <td>2.200704</td>\n",
              "      <td>-0.664651</td>\n",
              "      <td>0.958330</td>\n",
              "      <td>...</td>\n",
              "      <td>2.164942</td>\n",
              "      <td>0.307878</td>\n",
              "      <td>0.289513</td>\n",
              "      <td>-2.400427</td>\n",
              "      <td>0.365596</td>\n",
              "      <td>1.162806</td>\n",
              "      <td>1.063170</td>\n",
              "      <td>-0.448974</td>\n",
              "      <td>0.763081</td>\n",
              "      <td>0.772512</td>\n",
              "      <td>-0.527502</td>\n",
              "      <td>-0.335754</td>\n",
              "      <td>-0.391964</td>\n",
              "      <td>0.484197</td>\n",
              "      <td>0.680536</td>\n",
              "      <td>0.811878</td>\n",
              "      <td>-1.409013</td>\n",
              "      <td>0.922239</td>\n",
              "      <td>-0.927589</td>\n",
              "      <td>-1.019495</td>\n",
              "      <td>1.620049</td>\n",
              "      <td>-1.254732</td>\n",
              "      <td>-2.686923</td>\n",
              "      <td>0.599103</td>\n",
              "      <td>1.427806</td>\n",
              "      <td>-1.400661</td>\n",
              "      <td>-0.378462</td>\n",
              "      <td>0.058362</td>\n",
              "      <td>-0.674884</td>\n",
              "      <td>-0.929798</td>\n",
              "      <td>-0.535746</td>\n",
              "      <td>-1.361229</td>\n",
              "      <td>-0.840150</td>\n",
              "      <td>-0.495494</td>\n",
              "      <td>-2.824020</td>\n",
              "      <td>1.071420</td>\n",
              "      <td>0.077578</td>\n",
              "      <td>-1.415780</td>\n",
              "      <td>0.413741</td>\n",
              "      <td>-1.012781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.136987</td>\n",
              "      <td>0.391177</td>\n",
              "      <td>1.662034</td>\n",
              "      <td>0.496431</td>\n",
              "      <td>0.327838</td>\n",
              "      <td>-1.019523</td>\n",
              "      <td>0.703860</td>\n",
              "      <td>0.978327</td>\n",
              "      <td>0.115359</td>\n",
              "      <td>-0.414599</td>\n",
              "      <td>0.405612</td>\n",
              "      <td>-0.298265</td>\n",
              "      <td>0.829553</td>\n",
              "      <td>-0.606347</td>\n",
              "      <td>-0.580319</td>\n",
              "      <td>-0.308852</td>\n",
              "      <td>1.083191</td>\n",
              "      <td>0.408381</td>\n",
              "      <td>0.829244</td>\n",
              "      <td>1.129986</td>\n",
              "      <td>-0.512760</td>\n",
              "      <td>-0.323033</td>\n",
              "      <td>-0.640646</td>\n",
              "      <td>0.558617</td>\n",
              "      <td>-0.699157</td>\n",
              "      <td>-0.590015</td>\n",
              "      <td>-0.699474</td>\n",
              "      <td>-0.151121</td>\n",
              "      <td>-0.085373</td>\n",
              "      <td>0.177244</td>\n",
              "      <td>-0.563481</td>\n",
              "      <td>-0.552638</td>\n",
              "      <td>0.490241</td>\n",
              "      <td>0.789883</td>\n",
              "      <td>1.422918</td>\n",
              "      <td>1.493045</td>\n",
              "      <td>-0.300187</td>\n",
              "      <td>-0.277215</td>\n",
              "      <td>-0.882102</td>\n",
              "      <td>-0.600840</td>\n",
              "      <td>...</td>\n",
              "      <td>0.931024</td>\n",
              "      <td>-1.324186</td>\n",
              "      <td>1.635245</td>\n",
              "      <td>-0.423677</td>\n",
              "      <td>2.494555</td>\n",
              "      <td>0.569088</td>\n",
              "      <td>1.230374</td>\n",
              "      <td>0.222765</td>\n",
              "      <td>-0.841565</td>\n",
              "      <td>-1.671298</td>\n",
              "      <td>1.092262</td>\n",
              "      <td>-0.016988</td>\n",
              "      <td>0.120991</td>\n",
              "      <td>1.273939</td>\n",
              "      <td>0.572872</td>\n",
              "      <td>0.900999</td>\n",
              "      <td>1.052675</td>\n",
              "      <td>0.656173</td>\n",
              "      <td>-0.753558</td>\n",
              "      <td>-0.155229</td>\n",
              "      <td>0.371567</td>\n",
              "      <td>-1.211342</td>\n",
              "      <td>0.267750</td>\n",
              "      <td>-0.397498</td>\n",
              "      <td>-0.856035</td>\n",
              "      <td>1.443539</td>\n",
              "      <td>2.148654</td>\n",
              "      <td>-0.364822</td>\n",
              "      <td>0.197688</td>\n",
              "      <td>-0.044174</td>\n",
              "      <td>-0.030769</td>\n",
              "      <td>0.612792</td>\n",
              "      <td>0.157824</td>\n",
              "      <td>-0.585255</td>\n",
              "      <td>-0.669572</td>\n",
              "      <td>0.511266</td>\n",
              "      <td>1.128935</td>\n",
              "      <td>-0.203844</td>\n",
              "      <td>0.291813</td>\n",
              "      <td>0.700964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.057269</td>\n",
              "      <td>-1.272483</td>\n",
              "      <td>1.042172</td>\n",
              "      <td>0.293039</td>\n",
              "      <td>0.152190</td>\n",
              "      <td>0.489288</td>\n",
              "      <td>1.309904</td>\n",
              "      <td>-0.029723</td>\n",
              "      <td>0.527069</td>\n",
              "      <td>1.120779</td>\n",
              "      <td>-1.050842</td>\n",
              "      <td>0.219766</td>\n",
              "      <td>-0.193377</td>\n",
              "      <td>1.751008</td>\n",
              "      <td>-0.023067</td>\n",
              "      <td>1.201970</td>\n",
              "      <td>-1.209234</td>\n",
              "      <td>-0.256214</td>\n",
              "      <td>0.078142</td>\n",
              "      <td>0.065287</td>\n",
              "      <td>-1.358339</td>\n",
              "      <td>-1.020540</td>\n",
              "      <td>2.362678</td>\n",
              "      <td>1.541697</td>\n",
              "      <td>-0.139888</td>\n",
              "      <td>-0.272272</td>\n",
              "      <td>-0.332100</td>\n",
              "      <td>-0.212778</td>\n",
              "      <td>-1.032418</td>\n",
              "      <td>0.054423</td>\n",
              "      <td>0.349978</td>\n",
              "      <td>0.427400</td>\n",
              "      <td>-0.348927</td>\n",
              "      <td>0.405871</td>\n",
              "      <td>-0.972370</td>\n",
              "      <td>0.257894</td>\n",
              "      <td>0.288751</td>\n",
              "      <td>-0.164638</td>\n",
              "      <td>-0.159304</td>\n",
              "      <td>0.292241</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.145294</td>\n",
              "      <td>-0.509625</td>\n",
              "      <td>1.556164</td>\n",
              "      <td>1.622063</td>\n",
              "      <td>0.977065</td>\n",
              "      <td>2.318903</td>\n",
              "      <td>-1.929682</td>\n",
              "      <td>-0.243312</td>\n",
              "      <td>2.907282</td>\n",
              "      <td>-1.771985</td>\n",
              "      <td>1.201812</td>\n",
              "      <td>-0.540849</td>\n",
              "      <td>0.435901</td>\n",
              "      <td>-1.367740</td>\n",
              "      <td>-0.062243</td>\n",
              "      <td>-0.793462</td>\n",
              "      <td>0.109602</td>\n",
              "      <td>-0.230873</td>\n",
              "      <td>-0.831521</td>\n",
              "      <td>1.433624</td>\n",
              "      <td>-2.280423</td>\n",
              "      <td>-0.203550</td>\n",
              "      <td>-0.015494</td>\n",
              "      <td>-1.148940</td>\n",
              "      <td>-2.260907</td>\n",
              "      <td>0.715518</td>\n",
              "      <td>1.237147</td>\n",
              "      <td>0.948706</td>\n",
              "      <td>-1.077835</td>\n",
              "      <td>-0.649029</td>\n",
              "      <td>-1.404243</td>\n",
              "      <td>-0.068748</td>\n",
              "      <td>0.706241</td>\n",
              "      <td>-1.411049</td>\n",
              "      <td>-0.434626</td>\n",
              "      <td>-1.183047</td>\n",
              "      <td>-1.766813</td>\n",
              "      <td>1.350821</td>\n",
              "      <td>-1.633377</td>\n",
              "      <td>1.879864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>-0.026202</td>\n",
              "      <td>-0.658905</td>\n",
              "      <td>-0.632236</td>\n",
              "      <td>-0.725185</td>\n",
              "      <td>-0.489013</td>\n",
              "      <td>-0.078675</td>\n",
              "      <td>1.069693</td>\n",
              "      <td>1.151664</td>\n",
              "      <td>0.189983</td>\n",
              "      <td>0.746371</td>\n",
              "      <td>1.683763</td>\n",
              "      <td>2.020756</td>\n",
              "      <td>1.586811</td>\n",
              "      <td>-0.014815</td>\n",
              "      <td>0.087060</td>\n",
              "      <td>0.313171</td>\n",
              "      <td>0.425626</td>\n",
              "      <td>-0.749503</td>\n",
              "      <td>-1.326159</td>\n",
              "      <td>-1.493368</td>\n",
              "      <td>-0.664584</td>\n",
              "      <td>-0.757412</td>\n",
              "      <td>-0.600256</td>\n",
              "      <td>-0.832602</td>\n",
              "      <td>-0.524164</td>\n",
              "      <td>-0.475705</td>\n",
              "      <td>-0.319067</td>\n",
              "      <td>-0.819087</td>\n",
              "      <td>1.157670</td>\n",
              "      <td>-0.437214</td>\n",
              "      <td>0.063380</td>\n",
              "      <td>-0.700119</td>\n",
              "      <td>0.101800</td>\n",
              "      <td>-0.765327</td>\n",
              "      <td>-0.343577</td>\n",
              "      <td>-1.035043</td>\n",
              "      <td>0.142628</td>\n",
              "      <td>1.908703</td>\n",
              "      <td>-0.915491</td>\n",
              "      <td>-1.125506</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.777694</td>\n",
              "      <td>0.337082</td>\n",
              "      <td>0.073986</td>\n",
              "      <td>0.694256</td>\n",
              "      <td>-0.315985</td>\n",
              "      <td>-0.822070</td>\n",
              "      <td>0.751844</td>\n",
              "      <td>0.087859</td>\n",
              "      <td>-0.180756</td>\n",
              "      <td>0.800733</td>\n",
              "      <td>1.238968</td>\n",
              "      <td>0.458369</td>\n",
              "      <td>0.328843</td>\n",
              "      <td>-0.485749</td>\n",
              "      <td>0.963175</td>\n",
              "      <td>-0.983811</td>\n",
              "      <td>0.619996</td>\n",
              "      <td>-0.080017</td>\n",
              "      <td>0.352460</td>\n",
              "      <td>-0.178292</td>\n",
              "      <td>-0.501311</td>\n",
              "      <td>0.074827</td>\n",
              "      <td>1.503647</td>\n",
              "      <td>0.530572</td>\n",
              "      <td>1.002276</td>\n",
              "      <td>0.408172</td>\n",
              "      <td>-0.896642</td>\n",
              "      <td>0.890409</td>\n",
              "      <td>-0.682928</td>\n",
              "      <td>-0.449538</td>\n",
              "      <td>-1.596938</td>\n",
              "      <td>0.784325</td>\n",
              "      <td>-1.668093</td>\n",
              "      <td>0.792704</td>\n",
              "      <td>0.354541</td>\n",
              "      <td>1.860747</td>\n",
              "      <td>-1.013132</td>\n",
              "      <td>-0.625869</td>\n",
              "      <td>-1.521074</td>\n",
              "      <td>-1.557638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>-1.764498</td>\n",
              "      <td>-0.596178</td>\n",
              "      <td>0.368692</td>\n",
              "      <td>0.213806</td>\n",
              "      <td>0.634137</td>\n",
              "      <td>0.305659</td>\n",
              "      <td>-0.373702</td>\n",
              "      <td>-0.617016</td>\n",
              "      <td>-0.152767</td>\n",
              "      <td>-0.498762</td>\n",
              "      <td>-1.011378</td>\n",
              "      <td>-0.204235</td>\n",
              "      <td>-0.951458</td>\n",
              "      <td>-1.404448</td>\n",
              "      <td>-0.166131</td>\n",
              "      <td>-0.777725</td>\n",
              "      <td>-1.494261</td>\n",
              "      <td>-0.585374</td>\n",
              "      <td>-0.980379</td>\n",
              "      <td>-1.267077</td>\n",
              "      <td>-0.406083</td>\n",
              "      <td>-0.914221</td>\n",
              "      <td>0.906484</td>\n",
              "      <td>-0.685097</td>\n",
              "      <td>0.531622</td>\n",
              "      <td>0.204639</td>\n",
              "      <td>-0.945133</td>\n",
              "      <td>-0.811609</td>\n",
              "      <td>-1.464510</td>\n",
              "      <td>-0.879658</td>\n",
              "      <td>-0.014429</td>\n",
              "      <td>-1.382402</td>\n",
              "      <td>-1.077435</td>\n",
              "      <td>-1.276027</td>\n",
              "      <td>0.384779</td>\n",
              "      <td>1.023236</td>\n",
              "      <td>-1.778237</td>\n",
              "      <td>-0.311591</td>\n",
              "      <td>-0.824269</td>\n",
              "      <td>-1.098260</td>\n",
              "      <td>...</td>\n",
              "      <td>1.077178</td>\n",
              "      <td>0.238872</td>\n",
              "      <td>3.029303</td>\n",
              "      <td>0.237925</td>\n",
              "      <td>0.071915</td>\n",
              "      <td>0.044077</td>\n",
              "      <td>1.089707</td>\n",
              "      <td>-0.535304</td>\n",
              "      <td>0.393201</td>\n",
              "      <td>-0.780447</td>\n",
              "      <td>-0.621051</td>\n",
              "      <td>0.630422</td>\n",
              "      <td>0.043146</td>\n",
              "      <td>-1.669693</td>\n",
              "      <td>1.877549</td>\n",
              "      <td>-1.391170</td>\n",
              "      <td>-0.191442</td>\n",
              "      <td>0.268573</td>\n",
              "      <td>-0.684569</td>\n",
              "      <td>-0.465439</td>\n",
              "      <td>-0.353017</td>\n",
              "      <td>0.986490</td>\n",
              "      <td>0.547602</td>\n",
              "      <td>-0.410529</td>\n",
              "      <td>-0.222575</td>\n",
              "      <td>-0.536192</td>\n",
              "      <td>0.448637</td>\n",
              "      <td>0.056587</td>\n",
              "      <td>2.088166</td>\n",
              "      <td>-0.735185</td>\n",
              "      <td>-0.299822</td>\n",
              "      <td>0.034408</td>\n",
              "      <td>-1.381918</td>\n",
              "      <td>-0.100117</td>\n",
              "      <td>2.018984</td>\n",
              "      <td>2.637739</td>\n",
              "      <td>-0.967611</td>\n",
              "      <td>0.421639</td>\n",
              "      <td>-0.298897</td>\n",
              "      <td>-0.283857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>-0.176687</td>\n",
              "      <td>1.649737</td>\n",
              "      <td>-1.549789</td>\n",
              "      <td>-2.090515</td>\n",
              "      <td>-0.939293</td>\n",
              "      <td>-0.038439</td>\n",
              "      <td>-1.269945</td>\n",
              "      <td>-0.738830</td>\n",
              "      <td>-0.976061</td>\n",
              "      <td>-0.268316</td>\n",
              "      <td>0.385725</td>\n",
              "      <td>0.443298</td>\n",
              "      <td>0.868875</td>\n",
              "      <td>-0.058701</td>\n",
              "      <td>-0.392442</td>\n",
              "      <td>-0.419405</td>\n",
              "      <td>-0.512757</td>\n",
              "      <td>0.016544</td>\n",
              "      <td>0.804824</td>\n",
              "      <td>0.756670</td>\n",
              "      <td>0.128105</td>\n",
              "      <td>0.355990</td>\n",
              "      <td>-1.533655</td>\n",
              "      <td>-1.760107</td>\n",
              "      <td>-0.877640</td>\n",
              "      <td>-1.125041</td>\n",
              "      <td>0.360624</td>\n",
              "      <td>0.140962</td>\n",
              "      <td>0.398108</td>\n",
              "      <td>-1.031677</td>\n",
              "      <td>0.434076</td>\n",
              "      <td>-1.026974</td>\n",
              "      <td>0.742072</td>\n",
              "      <td>1.548900</td>\n",
              "      <td>-0.800660</td>\n",
              "      <td>1.129366</td>\n",
              "      <td>1.013700</td>\n",
              "      <td>0.085690</td>\n",
              "      <td>1.852541</td>\n",
              "      <td>0.714352</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.322206</td>\n",
              "      <td>0.016196</td>\n",
              "      <td>1.677576</td>\n",
              "      <td>-1.632139</td>\n",
              "      <td>0.502763</td>\n",
              "      <td>-1.454452</td>\n",
              "      <td>0.397737</td>\n",
              "      <td>0.170261</td>\n",
              "      <td>-1.069235</td>\n",
              "      <td>0.520708</td>\n",
              "      <td>-0.023377</td>\n",
              "      <td>-0.671373</td>\n",
              "      <td>-1.393492</td>\n",
              "      <td>1.107670</td>\n",
              "      <td>0.959545</td>\n",
              "      <td>0.504861</td>\n",
              "      <td>-1.689780</td>\n",
              "      <td>1.764541</td>\n",
              "      <td>-1.264936</td>\n",
              "      <td>0.068729</td>\n",
              "      <td>0.930980</td>\n",
              "      <td>1.035738</td>\n",
              "      <td>-0.210883</td>\n",
              "      <td>1.047884</td>\n",
              "      <td>1.127025</td>\n",
              "      <td>-0.184441</td>\n",
              "      <td>-0.633805</td>\n",
              "      <td>-0.855933</td>\n",
              "      <td>-0.451867</td>\n",
              "      <td>0.395087</td>\n",
              "      <td>0.006828</td>\n",
              "      <td>-0.975601</td>\n",
              "      <td>1.445979</td>\n",
              "      <td>0.593415</td>\n",
              "      <td>1.272336</td>\n",
              "      <td>-1.030874</td>\n",
              "      <td>0.675791</td>\n",
              "      <td>1.125456</td>\n",
              "      <td>0.203103</td>\n",
              "      <td>0.912194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>2.288371</td>\n",
              "      <td>2.832984</td>\n",
              "      <td>-0.468935</td>\n",
              "      <td>-1.010290</td>\n",
              "      <td>-0.272277</td>\n",
              "      <td>-0.691444</td>\n",
              "      <td>-0.626932</td>\n",
              "      <td>-0.936914</td>\n",
              "      <td>0.614128</td>\n",
              "      <td>0.165313</td>\n",
              "      <td>-0.424991</td>\n",
              "      <td>-0.954574</td>\n",
              "      <td>-0.961918</td>\n",
              "      <td>-0.403619</td>\n",
              "      <td>0.145125</td>\n",
              "      <td>0.385477</td>\n",
              "      <td>0.911646</td>\n",
              "      <td>0.518672</td>\n",
              "      <td>1.391191</td>\n",
              "      <td>1.078448</td>\n",
              "      <td>0.112098</td>\n",
              "      <td>-0.070749</td>\n",
              "      <td>-1.191127</td>\n",
              "      <td>-1.228291</td>\n",
              "      <td>-0.164342</td>\n",
              "      <td>-0.518844</td>\n",
              "      <td>0.508102</td>\n",
              "      <td>0.412389</td>\n",
              "      <td>0.081177</td>\n",
              "      <td>-0.411564</td>\n",
              "      <td>-0.830449</td>\n",
              "      <td>-0.867447</td>\n",
              "      <td>-0.879055</td>\n",
              "      <td>-1.521471</td>\n",
              "      <td>-0.772275</td>\n",
              "      <td>-1.291119</td>\n",
              "      <td>1.136675</td>\n",
              "      <td>0.634924</td>\n",
              "      <td>-0.493608</td>\n",
              "      <td>-0.031602</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.911162</td>\n",
              "      <td>-0.870166</td>\n",
              "      <td>0.369694</td>\n",
              "      <td>0.548692</td>\n",
              "      <td>0.978675</td>\n",
              "      <td>-1.470184</td>\n",
              "      <td>-1.258347</td>\n",
              "      <td>0.042651</td>\n",
              "      <td>-0.291656</td>\n",
              "      <td>0.443233</td>\n",
              "      <td>0.008726</td>\n",
              "      <td>0.664343</td>\n",
              "      <td>-1.602157</td>\n",
              "      <td>2.508723</td>\n",
              "      <td>-2.652287</td>\n",
              "      <td>2.429169</td>\n",
              "      <td>0.152235</td>\n",
              "      <td>-0.230617</td>\n",
              "      <td>-0.128753</td>\n",
              "      <td>-0.725586</td>\n",
              "      <td>2.263243</td>\n",
              "      <td>1.219485</td>\n",
              "      <td>1.431461</td>\n",
              "      <td>-0.768432</td>\n",
              "      <td>-0.764827</td>\n",
              "      <td>-1.429780</td>\n",
              "      <td>-2.061141</td>\n",
              "      <td>0.975162</td>\n",
              "      <td>0.668408</td>\n",
              "      <td>0.544281</td>\n",
              "      <td>-1.509899</td>\n",
              "      <td>-0.969535</td>\n",
              "      <td>2.475998</td>\n",
              "      <td>0.431115</td>\n",
              "      <td>-2.003263</td>\n",
              "      <td>-0.838497</td>\n",
              "      <td>1.858790</td>\n",
              "      <td>-1.061877</td>\n",
              "      <td>0.418329</td>\n",
              "      <td>-0.136945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>-0.730438</td>\n",
              "      <td>-0.616909</td>\n",
              "      <td>0.305384</td>\n",
              "      <td>0.424322</td>\n",
              "      <td>0.658946</td>\n",
              "      <td>1.709071</td>\n",
              "      <td>0.578482</td>\n",
              "      <td>-0.224237</td>\n",
              "      <td>0.423245</td>\n",
              "      <td>0.694492</td>\n",
              "      <td>0.339734</td>\n",
              "      <td>-0.558621</td>\n",
              "      <td>0.731838</td>\n",
              "      <td>-1.496395</td>\n",
              "      <td>0.361402</td>\n",
              "      <td>-0.087774</td>\n",
              "      <td>-0.199654</td>\n",
              "      <td>-0.628768</td>\n",
              "      <td>-1.139097</td>\n",
              "      <td>-0.769973</td>\n",
              "      <td>-1.316798</td>\n",
              "      <td>-0.112202</td>\n",
              "      <td>-1.426408</td>\n",
              "      <td>-0.933422</td>\n",
              "      <td>0.105656</td>\n",
              "      <td>1.268760</td>\n",
              "      <td>0.275651</td>\n",
              "      <td>0.182214</td>\n",
              "      <td>-0.270851</td>\n",
              "      <td>-0.558567</td>\n",
              "      <td>0.033784</td>\n",
              "      <td>-0.036653</td>\n",
              "      <td>-0.796700</td>\n",
              "      <td>-1.841536</td>\n",
              "      <td>-1.836372</td>\n",
              "      <td>-0.175732</td>\n",
              "      <td>0.402994</td>\n",
              "      <td>-0.642246</td>\n",
              "      <td>0.586675</td>\n",
              "      <td>1.138353</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.142933</td>\n",
              "      <td>1.390537</td>\n",
              "      <td>0.579313</td>\n",
              "      <td>-0.340355</td>\n",
              "      <td>-1.883580</td>\n",
              "      <td>-0.918831</td>\n",
              "      <td>-0.854564</td>\n",
              "      <td>0.115233</td>\n",
              "      <td>-0.480486</td>\n",
              "      <td>-0.306707</td>\n",
              "      <td>0.921139</td>\n",
              "      <td>-1.111258</td>\n",
              "      <td>-0.048091</td>\n",
              "      <td>-1.324248</td>\n",
              "      <td>0.115888</td>\n",
              "      <td>-0.551906</td>\n",
              "      <td>0.008620</td>\n",
              "      <td>2.122125</td>\n",
              "      <td>0.256191</td>\n",
              "      <td>0.237769</td>\n",
              "      <td>-0.032154</td>\n",
              "      <td>1.130752</td>\n",
              "      <td>0.868036</td>\n",
              "      <td>-0.502445</td>\n",
              "      <td>-0.306356</td>\n",
              "      <td>1.227910</td>\n",
              "      <td>0.320798</td>\n",
              "      <td>1.051188</td>\n",
              "      <td>0.839369</td>\n",
              "      <td>0.422198</td>\n",
              "      <td>0.438078</td>\n",
              "      <td>0.765650</td>\n",
              "      <td>0.605827</td>\n",
              "      <td>0.208425</td>\n",
              "      <td>1.609053</td>\n",
              "      <td>1.113432</td>\n",
              "      <td>-2.169528</td>\n",
              "      <td>-0.147885</td>\n",
              "      <td>-0.837889</td>\n",
              "      <td>-0.134696</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>87 rows × 2390 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       aal-0     aal-1     aal-2  ...  smith70-67  smith70-68  smith70-69\n",
              "0   0.903504 -1.379881  1.815419  ...    1.106303    0.319606   -0.563350\n",
              "1  -1.005250 -0.774012  0.297203  ...    0.692951    0.758725    2.094716\n",
              "2  -0.570857  0.659692 -0.606319  ...   -1.415780    0.413741   -1.012781\n",
              "3   2.136987  0.391177  1.662034  ...   -0.203844    0.291813    0.700964\n",
              "4  -1.057269 -1.272483  1.042172  ...    1.350821   -1.633377    1.879864\n",
              "..       ...       ...       ...  ...         ...         ...         ...\n",
              "82 -0.026202 -0.658905 -0.632236  ...   -0.625869   -1.521074   -1.557638\n",
              "83 -1.764498 -0.596178  0.368692  ...    0.421639   -0.298897   -0.283857\n",
              "84 -0.176687  1.649737 -1.549789  ...    1.125456    0.203103    0.912194\n",
              "85  2.288371  2.832984 -0.468935  ...   -1.061877    0.418329   -0.136945\n",
              "86 -0.730438 -0.616909  0.305384  ...   -0.147885   -0.837889   -0.134696\n",
              "\n",
              "[87 rows x 2390 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yUPhE5w1d8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mid = mid.reset_index()\n",
        "mid['index'] = mid['index'].astype(int)\n",
        "result = result.reset_index()\n",
        "result['index'] = result['index'].astype(int)\n",
        "result1 = mid.join(result.set_index('index'), on='index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5q-soQa3LeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result1.to_csv('/content/drive/My Drive/Datasets/Schizophrenia and Bipolar Disorder Classification/data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}